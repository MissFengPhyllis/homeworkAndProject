{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework assignment - Fruits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsc2OQrvXmGrTC9Mn+5bI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MissFengPhyllis/homeworkAndProject/blob/master/Another_assignment_Fruits20200514.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et5Ly7OPM6qi",
        "colab_type": "text"
      },
      "source": [
        "## Homework assignment - Fruits\n",
        "This notebook is the stub you have to fill out for the homework. Read the task description and implement the empty code cells. Each section represents a stage along implementing an image classifier from loading and inspecting the dataset to making something working. The section descriptions contain what to do in that step.\n",
        "\n",
        "Copy this notebook to your drive (File -> Save a copy in Drive), edit it and upload the final ipynb file to canvas.elte.hu or upload the link to the Colab notebook itself. If you have your own machine with Jupyter installed, you can work there as well.\n",
        "\n",
        "Note Make sure the notebook is using GPU accelerataion in Edit -> Notebook settings, otherwise training and evaluation can be very slow.\n",
        "\n",
        "## Task description\n",
        "Your task is to implement a deep learning classifier of fruit images. The dataset contains segmented images of 60 different fruits. You'll have to implement a convolutional network.\n",
        "\n",
        "## Rules and Comments\n",
        "This is an ML class so to pass the homework you do have to implement a working classifier, just loading the data is not enough.\n",
        "As always, copying others' code will make you fail the homework automatically (and thus the course)\n",
        "Make sure your code can be run from an empty state (use Runtime -> Run all in the menu after restarting the notebook)\n",
        "Feel free to add more code cells as needed. But don't put code into external Python files to ease the reviewing.\n",
        "Please add your name and Neptun ID in the box below for easier identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23kMqkoyNQrD",
        "colab_type": "text"
      },
      "source": [
        "**Name: Feng Lijiao**\n",
        "\n",
        "**Neptun ID: H2MI9D**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523TuxyCE1aZ",
        "colab_type": "code",
        "outputId": "5acca862-9f55-4413-cc76-ca1f0394096e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Keras 2.3.1 has a bug in evalutation, downgrade it\n",
        "%tensorflow_version 1.x\n",
        "!pip install -U keras==2.2.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqxXNAP6E6wj",
        "colab_type": "code",
        "outputId": "d76698b0-8b15-4f88-b73f-08312c04f2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsxOvO9zE9jS",
        "colab_type": "code",
        "outputId": "3f5ac008-cc74-4c80-d7df-63da865af901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://vegesm.web.elte.hu/fruits_small.zip\n",
        "!unzip fruits_small.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-12 08:50:28--  http://vegesm.web.elte.hu/fruits_small.zip\n",
            "Resolving vegesm.web.elte.hu (vegesm.web.elte.hu)... 157.181.1.225\n",
            "Connecting to vegesm.web.elte.hu (vegesm.web.elte.hu)|157.181.1.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 186322919 (178M) [application/zip]\n",
            "Saving to: ‘fruits_small.zip’\n",
            "\n",
            "fruits_small.zip    100%[===================>] 177.69M  4.04MB/s    in 3m 7s   \n",
            "\n",
            "2020-05-12 08:53:36 (974 KB/s) - ‘fruits_small.zip’ saved [186322919/186322919]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LiQlb7wFJCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import skimage\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color,data,transform,io\n",
        "from sklearn.utils import shuffle\n",
        "import keras\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9gKspTkOFSP",
        "colab_type": "text"
      },
      "source": [
        "Save the path and separate the paths of the test set and the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnqScMRSNkLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/fruits-small/\" \n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"test/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzn6ihBDM-w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Get the picture data under the corresponding path folder\n",
        "def load_data(dir_path):\n",
        "    images=[] ##Create an empty list to store the picture collection\n",
        "    labels=[] ##Create an empty list to store the tag set\n",
        "    no5_imgs=[] ##Create an empty list to store the fifth picture under each folder\n",
        "    labels_no5=[] ##Create an empty list to store the folder name corresponding to the fifth picture\n",
        "    lab=os.listdir(dir_path)\n",
        "    n=0\n",
        "    for l in lab:\n",
        "      img=os.listdir(dir_path+l) ##img is the folder under the corresponding path\n",
        "      for i in img:\n",
        "          img_path=dir_path+l+'/'+i ##If yes, get the image path\n",
        "          labels.append(int(n)) ##Store the iteration number n of the outer loop in labels\n",
        "          images.append(skimage.io.imread(img_path)) ##Read the corresponding path image and store it in datasets\n",
        "      n+=1\n",
        "      no5_img=format_path(img) ##Arrange the pictures in the correct order to facilitate the fifth picture\n",
        "      img5_path=dir_path+l+'/'+no5_img\n",
        "      labels_no5.append(l)\n",
        "      no5_imgs.append(skimage.io.imread(img5_path)) ##The fifth picture of each category is read out and stored in the data set no5_imgs\n",
        "    return images,labels,no5_imgs,labels_no5 ##The storage order of the images in the returned images is different from the storage order in the actual folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoIl-3pINxcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Function for sequentially reading files in a folder\n",
        "def format_path(img):  ## img is the result of os.listdir (label folder)   \n",
        "    yes_int=[] ##The new list is used to store the file name of the first item that can be converted into an integer\n",
        "    for s in range(len(img)): ##Iterate\n",
        "        img[s] = img[s].split('_') ##Separate file names with \"_\" as a separator\n",
        "        if(is_number(img[s][0])): ##Determine whether the first part of the file name can be converted to an integer\n",
        "            img[s][0]=int(img[s][0]) ##Convert the first part of the file name to an integer\n",
        "            yes_int.append(img[s]) ##Put the file name in the list without r\n",
        "    yes_int.sort() ##Sort the list of file names that can be converted to integer\n",
        "    for yi in range(len(yes_int)): ##variable\n",
        "        yes_int[yi][0]=str(yes_int[yi][0]) ##Convert the previous part to integer and then back to the string\n",
        "        yes_int[yi]=yes_int[yi][0]+'_'+yes_int[yi][1] ##Perform stitching\n",
        "    no5_img=yes_int[4]\n",
        "    return no5_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef0GmLQ-Ny3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Determine whether a piece of data can be converted to plastic\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        " \n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42owZfrFNaPR",
        "colab_type": "code",
        "outputId": "7889a769-ad64-4a51-8ec0-2fe0df460382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Final train data set and label\n",
        "images,labels,no5_imgs,labels_no5 = load_data(train_dir)\n",
        "print(len(images),len(labels),len(no5_imgs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30468 30468 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3sJcu4mOGLK",
        "colab_type": "code",
        "outputId": "6d15f15a-d0a9-403c-d2f5-88e847597d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "##Final test data set and label\n",
        "images_test,labels_test,no5_imgs_test,labels_no5_test = load_data(validation_dir)\n",
        "print(len(images_test),len(labels_test),len(no5_imgs_test),len(labels_no5_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10332 10332 60 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCcaBQl0Pzpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Define the fifth picture visualization function\n",
        "import random\n",
        "def display_no5_img(no5_imgs,labels_no5):\n",
        "    fig = plt.figure(figsize=(15,15)) ##The displayed size is15*15\n",
        "    for i in range(len(labels_no5)):\n",
        "        plt.subplot(11,7,(i+1)) ##Displayed as 11 lines, 7 per line\n",
        "        plt.title(\"{0}\".format(labels_no5[i])) ##Show title\n",
        "        plt.imshow(no5_imgs[i])  ##display image\n",
        "        plt.axis('off') ##Don't show axis\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO8wVwZMP2-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Call display function\n",
        "import random\n",
        "def display_no5_img_4(dict_no5):\n",
        "  fig = plt.figure(figsize=(15,15)) ##The displayed size is 15*15\n",
        "  for i in range(len(dict_no5)):\n",
        "    # print(i) //Subscript of dictionary list\n",
        "    # print(dict_list_no5[i][0])//Picture title\n",
        "    # print(dict_list_no5[i][1])//Picture matrix\n",
        "    plt.subplot(11,7,(i+1))\n",
        "    label = dict_no5[i][0]\n",
        "    img = dict_no5[i][1]\n",
        "    plt.title(\"{0}\".format(label))\n",
        "    plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAOYlux8P1Wn",
        "colab_type": "text"
      },
      "source": [
        "show random 4 picture and the class name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2gyaNIWvqcp",
        "colab_type": "code",
        "outputId": "0ee0165a-16c5-4059-a7b0-108079f55c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "dict_no5 = zip(labels_no5,no5_imgs)\n",
        "dict_list_no5 = list(dict_no5) \n",
        "random_list = random.sample(dict_list_no5,4)\n",
        "display_no5_img_4(random_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAABuCAYAAAAULnuKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9ebQk133f9/ndW9Xdb5l9wQCDfSVBgCJICNRCUrQkSqQUHVmKZcmyfCw5shPrOFFO7Fg+iRI7kXyk2DqHlk/i0LJlS1YiK1psUVxEihSFHQQIEIN9MAswy5uZN2/feqmqe+8vf9xb3T0PM8AAg5k3wPT3oAfd1VXV9epX9/627+93RVUZYYQRRhhhhBE2DmajL2CEEUYYYYQRrnSMlPEII4wwwggjbDBGyniEEUYYYYQRNhgjZTzCCCOMMMIIG4yRMh5hhBFGGGGEDcZIGY8wwggjjDDCBmOkjNdBRH5aRB5+ne//VET+5qW8phEGEBEVkVvT+98SkV/e6Gsa4fKCiNwvIj+70dcxwtkhIj8iIsdFZE1E7nkLx39URF6+GNeWzr8hOuBtUcYi8hMi8riItEVkJr3/ORGRt+P8F3htL4vIjw99/s40oa/ftioi2RudT1U/paq/nY57XaGdx7X9oIg8LCJLIjItIv9WRDa91fNd7hCRIyJSisjOddufTjK5cWOubISLiST3bpp8TycjanKjrwtARL5NRL4iIgsiMisifyAiV2/0db2duAzn518D/p6qTqrq02/2YFV9SFXvqD+n5+t7z7X/5awDhnHBylhE/j7w68A/B/YAVwH/DfCdQOMcx9gL/d03gQeBjw19/hiw/yzbHlNVdwmvC2AL8MvANcB7gb3E+/huxqvAX6s/iMjdwPjGXU7/Ouy6z284KEd4U/ghVZ0EPgjcC/ziBl9PjW3AbwA3AjcAq8C/38gLejtxmc7PNwAvnOO3L8a4u5x1wACq+pZfRGXSBv7LN9jvt4D/G/hi2v97gR8EngZWgOPAPxna/0ZAgb8DnAROAf9g6HsD/CPgMDAP/D6w/Ry//TeA54Y+fxH46bNs+8X0/qeBh4nW2yJReXxqaN/7gZ8lKs8e4IE1YCl930zHHgNOA58Bxs7zfv7o8HW9217AEeIk/I2hbb8G/M9J3jfW93fo+58GHh76rMCtQ8/VZ4CvECfRB4AbhvZ9T/puAXgZ+Ktv8EweAX4BeBYogP8R+KN1f8O/BH59o+/lO+mV7uv3Dn3+58Dn0/tvAx4FloBngI8P7fczwEtJtq8A//W68/4wsI84hxwGPpm23w/8EvBIOvbPgJ3nea0fBFY3+p69Tff9spqf09y4lo5tA4eHno/hcZcNj/Oha/zl9P7jwFR6/ztAALrp3P/wLH/fO0IHXKiwPwk4IDsPYS8TrTEDtNINvTt9fn+66L+8Ttj/EZhI+82SBjTw88DXgWvTH/6vgf94jt++IQlre/qtGWAsPWD1tmXgY0OCqIC/DVjg76YHToYFMSy0db/3aeBP0rk3AZ8DfuU87+e/AH5vowfxxXqRJmWiYnxvur9TSUZvVRmvEq3aJtEDeDh9N5Fk/DPEwX0PMAfc+TrP5BHi5H5dekauJk4aW9MxWXp+PrTR9/Kd9GJIGad7+wJRWe4lTtY/kGTwifR5V9r3B4FbAAG+C+gAH0zf3Zfk94l07F7gPem7+4mK4PYkx/uBXz3Pa/3vga9v9D17m+77ZTk/81pFe8a4O8c+v8VZlPH65+scf987QgdcqLB/Cphet622crtDf9xvAf/hDc71L4BPrxP2e4a+/2fAb6b3LwHfM/Td1enmnfWhS8L6YeKE/Eja9ntD27pAc+jmHho6djxdy543EgRx0mgDtwxt+3bg1fO4l58gWmG3b/QgvlgvBsr4F4FfIU4WX2FgCd/Im1fGvzf03STRSr0O+HHgoXW//6+Bf3yuZzJd399at+1Pgb+d3v8XwIsbfR/faa90X9fSvHAU+FfEyfAXgN9Zt++Xgb95jvP8MfDzQ7L89Dn2u5/k5aTPPwd86Tyu8/3EKMpHN/qevU33/bKcnzm7Ml4/7t42ZTy0z2WtAy40Pj8P7BSRTFOsXVW/A0BEpjgzJ318+EAR+TDwq8BdxNxFE/iDdecfPuYo0QKDaOn8ZxEJQ997Yj7kxFmus84ZHAMeStseHtr2hKoWQ/tP129UtZN4DudDONlFFNxTQ9wIIVpX54SIfBvwu8BfUdUD5/E773T8DlEmNwH/4QLP1X9GVHVNRBaIOfgbgA+LyNLQvln67dcc+zrbfptoGf8b4uT2O685YoTzwV9W1a8ObxCRG4AfE5EfGtqcA3+Rvv8U8I+JHq4hjq3n0n7XEUOL58L00PsObzB+E0P/T4nK/qHX2/cdhHfK/Pya378IuKx1AFw4gesxYoz/h89jX133+XeJrvx1qrqFGFdfz+67buj99cRQAUTBfUpVtw69Wqp6LkHXgvgoA0E8NLTtwfO4/rNh/d80R7Sw3jd0XVs0ElfOikTt/xOiZfjnb/E63lFQ1aPEPMwPAP9p3ddtziR07XmD0/WfkcTQ3U58To4DD6x7RiZV9e8OX8rZLm/d5z8G3i8idxE94//3Da5nhPPHcaJnPCyjCVX9VRFpAn9EzL1dpapbicpXho695e24iGQUfBX4JVV9Nxlb75T5+Wy/3+H854GzjeP1uGx1QI0LUsaqugT8b8C/EpG/IiKbRMSIyAeIuYTXwyZgQVV7InIf8JNn2ed/EZFxEXkfMff3/6XtnwH+aRpEiMguEXm9B+5BYijiY0RSB0QL+ybgL/HWBXEauFZEGgCqGoge1KdFZHe6tr0i8v1nOzhN8F8C/ltV/dxbvIZ3Kv4r4LtVtb1u+z7gR5Pcb037vR5+QEQ+kmTwS8R833Hg88DtIvI3RCRPr28Vkfe+mYtU1R7wh8TJ6QlVPfZmjh/hdfH/AD8kIt8vIlZEWiLycRG5loE3Ngu45CV/39Cxvwn8jIh8T5pz9orIe97sBYjIXuBrwP+pqp+58D/p8sE7aH4+G/YBP5mei08SOQPnwmng5jc432WpA4ZxwaVNqvrPgP8B+Ifpwk4T8zm/QMxPnAs/B/zvIrIK/K9Ext16PAAcAv4c+DVV/bO0/deJVtufpeO/Dnz4da7xAHFQT6cHtL5pTwCb3+A6Xw9fI5JRpkVkLm37hXTNXxeRFaLFfcc5jv/7xLDGb6YazDUROSvl/90GVT2sqk+e5atPAyXxOfpt3tgT/V1iKHMB+BAxlIyqrhIn758gWuzTwP9BnODfLH6bGIJ7N3lNG45kNP0w8D8Rx+dxIoPdJPn9d8R5YZGoDP5k6NgniArg00TyzQPE8Oibxc8SJ/J/MjQG197yH3WZ4Z0wP58DPw/8EDG//deJEapz4VeAX5TYr+EfnG2Hy1gH9FGzwy4rSGz+8CqQ60bWfY0wAiAi1xPrEveo6spGX88II2wkRvPzxcGoHeYII7wORMQQPYvfGyniEUYY4WJh1GVohBHOARGZIIb1jhLLsEYYYYQRLgouyDMWkU+mvp+HROQfvV0XpapHVFVGIZDLBxdL1pczVLWdGNjvS/nNdz2uRDlfqXirsh7NzxcHbzlnnPqXHiA2q5gCvgH8NVV98e27vBEuB4xkfWVgJOcrByNZX364EM/4PmKXkldUtWTQzWSEdx9Gsr4yMJLzlYORrC8zXEjOeC9ndk2Z4iz0dRH5O8SG4kxMTHzoPe85n1LA2ltfX2N+tu3Dnr30NznniMz1eg9FFbx3hBC3GyNkWY4xNh4pAgJGDPI2ry721FNPzanqrrf1pJcObyjrtybnN8L6qM1AJqqgGgiqkOTa6ZVoCLRaTVrNBsYYzv0srT//2yPvd7uc4UJlrZwhR9bd+TM2nCn/qizimJZAbDVM2tnQaLSIvsX6uUGG3rPu87m+Oz+822X9dszdOvTv4G7LuidgWNLrZXIm5Ix9hvarO1Ge9dm5sLF9qeR80QlcqvobxCXKuPfee/XJJ89WWnrG/mduEF4jF1Ul+EBVeZaXVuj21iiLDsFXcbCGwPzCHN5VBO/o9NbwwZFleTw2aDqpkmUZNovK11rB2pzNm3awadMutm7dyeYtW8gbDRBFpD5OiCRbob7c1yrvMx9KETn6pm7cOwxvVs6DQTh033RoYEl8oygQECyqQq+oOHJ0iscee4yDhw7Q6/UYHxtjy+YtHJs6wfTMLHuvvY577rmHj33k27l+724yCyEoRekoKgcBcmtptnKyzKBay5M40StpupA3PY7f7XKGtyhrrVDy+FEUtL6xIcpYbX+TEOh2ltHQZnb6FU4ee4HgFlhePILoKkYKrLGIUcQGsrzJ5q3Xk2XX4PQqbrr1PpoTu2i0JuK4xSIqUa5maFyKErs0AhgEC+mJG4ac4yF4t8v6rc3dBZCnebsEzVG1KIoYIIBooDJxfFkB1+1weP9zGN+mWJtDXI9mBsFXlLqGJ6BqCJpT+Rzb2MJ7P/Dt2OZmNGuQtcYwKogqRobn4lq+HrCIZkRvC+Qsyl7Xybn+dKnkfCHK+ARntkO7lnP3HX0TSApOAAJotKNU45Aoy4qVlSXm50+zurhEu71CCB2cb6NaEHyBqgcNiMQHxKiL9nOwgCAKIXiCOrq9kqAOkRA9ZZuzPNfCmEnGxnewdfserr7merbt3MXY2GTfqlsvSiVwxrAdzCzvBrztsl7/4L9WEcd9NClFRZidW+GRR5/gyaee5NSpY4RQUlWOsvDcddcHeN+dd7Jr9xzGtlhYXOGpp59nrHUf27ZMsP+ll3j4kcc4NTNPcJ4d27dz34fv44Mf+hbGWjm2tt61/t2Id4f4zhsXZ0wrRK81oBgUwRCSPWwQCagoAaFqz3H01efZ/+ID4E5hwiwZK1jt0JACazx5LkjmIUAWDLay6PwRSjNOJdvZN/d1yG7lhpu/g93X3sz4+NZ4ESYqfum3CRbQoSlQ+v+89vLP+s07GhdF1qpNRAANoI0oXwJi4pysJsNr/Qx4Fk8cYv7I05x66WEmsiUaZoU8K2m7grKq6JVQVhXeB1QFpwbPGHOHP4u3O5nYdgO3vfc+tDHOpu1XsXnrHnxSa0aJ41pMjKQlA1/688rlhQtRxt8AbhORm4hC/AnO3jLtTUMk2ae18QoE7+m020xNvcLc3DE6vUVwbdAqKuPQBgo0lBiJIUxUEVVEDQg4p2gIcQyiBPWgHkPAGoOQIz4HLKpN1tZOs9Y5wszcIbbvvJHrr38fO7bvJm9mA6Vxhs6NCnlg9b9rcNFkDQMZ1z6Jahwsznsq51Bgba3H57/wJR544CF6vQ7Od0E8jUaTTZs2sbKySlEVnDp5iqXFJfZecy0ShCcaz1NWBV/96peZPTkFoQIyduy+ms07rqEIGR/64J1sm2ycYS2rvDYgdgXgoshZEVCbAg11dCkAytTxKWZPz3HDTVdzYvoApw58lZXFIxiZJzMr5LaHFY81FiMGjMGrIiFgELxL222JzbrYbAXj56k600w9d4DpYx/gvd/y3WzavBtjm4iNHvhgDQPhjIF85eDijOnkRIlGBwqjKB5NkYfgCjq9Zab3P4X2Zlg6+U0a7jjXb55nPO9hpSKI0POBwgXG/RhF4SlLh/cB5z3KCqFaoOo2WFvex1Ov/hkdxhjffjN7b/kwd9z9EcYmd2CyPD53AcQKAUfkrV2esn7LylhVnYj8PeKSZxb4d6r6pls5DoelY3hBk5dJ8mCVsugxM32K06ePsLB4nMrPE2iTBQcENPRAC1RLBCV4jxUhBBdDI0hSwgFMPKb2f6wx0VpXgxFDCIoYAe0ixhJYo9trc+rkGivLS9x0013s3Xs9jdZYyknW2ngQ+j6PBTreUXi7ZH3mSQdvol0T5aFiUGBltc2zz73I8eMnsDbj+PETPProo6ytrRCCI2iFoDSbLXRS8P40RVmyurLKxMQm7rnnXsY2beYLf/pl5udnWVtbQEKJ1YpmY4JGY5xbb7uTpZUVDhw8wj1330IzM30jS1Xfdt7A5Y6LImcA0WifasrwqqJYEGHvddeSmcBLT3+FI0f/nLw4gJWKvJGnUZRBluOCx+QGxWOMYDWLKSejqFSohUwMNniarNKgg/dHaS+c5qn7X2bHzrvIx3ZAs8U119/C1m17EFOPU0M0wNdf9/lwVt6ZuFBZn6sKR5JDohJAHDE8bKk6a1RrM3QX9nP80IMw9yIN22bneJvGZIdGHshME0IT1ZwsU8YajkotZTOnKIWiEjpFSeVLVB1NU2BcQdlbIOsqS4uHmTvyJIf2fY077/kkN9x2H1t2XJ3C0gHFI5i+0S8pCjss5uFM96WW8wXljFX1i7z+MmZvdPxZP/ezST6wuDDPsaOHWFw4QVHO4XWJwAo+dDBkMTAsIelXmyxvQdUjIkkAxAkBP+yGRQ9MQcTEoIkWkAIoIiaeTxQrggah3a7Y/9I8i0u3cfPN72Pbtl0YY6MaUekbE++mQVvjQmV91nPSTw3HzxKl1ysqHnz4UT772c+xttJmbGyCxcUF1trLaCgJwaMqGGPBg69KVnodym4PkzW5as+17Lr6Ol546UVOnpzCl2u4YhXvK7LM0mwJnU6HAwcPceddd7P/pWe54ZodXL17e980CCj2XSS/88XFkHM6L4IHTFTECmWv4ODL+zjw/OfpLO3DuiUIXUxuCL5CjInj1Wj0ZBWMCMaDoYrKVA1BLFUIeHVk4sgxZJKRiSXwCkanmZt6hkrHwY5z8vBV7Nh5L7ff9T1Mbr8KNZEQJuuLS16fXfaOx9sxfw8brKqKeIOKohZUDVL1WDi6j5Xjj9GefooJO88OmWd8q4JxZE2PZKDkhNAA08KIYI0jR2l4pSFCK8spnSG30O5VlE5jCNxE471bLUNvjbHGEqtHT/CVA8+wec8HuffjP8Z7vuVbaU1OIJKdhRemSQeci/h36XB5duBSQ1EUnD41xYmpw6wsnySwTAjLQBuhwEodXEqEKiOol/SApO3JOtMUPQbQEBm29frV0tcGHqwjEDBqUc0QauEJqgEriivbnDjWQ33Frbfezbbte2LoI+WblET0eveFqt9eCKDaf+zrPG0AFpaXeOTRRzl14iS5yQheKMsC73qolinKmaHeUKoDOvhQglNyk9NeW+XRRx9h/8sv0eusEnwXX/aAgBelLEqcq3j6ySdZmJtn5vQx7rn7Nvbs3t63kk3MZbyb5t6Ng4JRQTEEiZKuipKDLz7Ovid+n1C+gK2WoDJY0wAUNQ5vS0wWJ3WDQRCshjj2pQE+jX4Fg8H0Q5DRkDYmp6EVwgJ5QynLBsE3MeUJVmemeOmb09x170/Q2HwVxkbDPZIzr8iw9VvGGU6VVjhgeaWH7c5z4uk/Ilt6HFseZ2urQyMrmWw0KXMDkiPkmGDieHbRCCYzYJuYxhgaPGSCOEsmwpjGub5X9qhcQCTgm2AblkZooRrYPKlU/gSzxxb50h8c49irP8j3/8hfJ5/cjBCwtfe+3i1mY4f8hipjkXhD1ltYvbU2UyeOMHXsZbrFLMEvEnSFuEykQwSMMUN0qdqb9YMwg0RlHEshUqMYNSAplwFEQkldKqGoWkQMGiL7ExxQotpFTIPguhjTIKjjxFSBhoI77vhWtm7fw6CsQmr9PRrOr4shCkUaFKoQBBaXV5hfmKeZ5xTtLjbL0eBihAKDD0QZieIqh/NlknEDV1ScPnWM06eO4XwgqKdXVuRZk62T4zQziazMqsfa8hyPPnSEsWZOt1PEy4DEwD0Xh3aEtwTVFIGCzto8Tz72BY68/GXoHSb3PagMqBLokZFhbAYSI1OqIc5UorGUDUGDQQxYGxBctLuxGE3RMqOIrTBBsMFgxZMZwAdE13C6Qm9lmUfvn+aO9/8Ee298H5LZIeNbMWb0BJwv6rncZ8LqwhrPP/J5JnsPs8c8Q8uu4jfldI3HZTnOtJC8F6OPwaIhA2MweXwGTJ7RaE2iYjG5Ym2gxEfZoTSzJmIyrHP0qgqL0KwmaJcem1vILdus0My6LK++xDe/NsvK6hwf/sRf5Zabb0FFo0ediIWXSzpqQ5VxPyydboaq0u12mDr6AlMnDlEUc2jtEWsPxcXBiSRSVvJI1SPGYySA9/RrENUAeWLIBkSj7xVCVNKacsf9WVhTmCrUPN4Yco5OXAUUBJ8RKMCUzEy/TLMxwR2tCcYmEmNzaAofOVavA4U+4S2Fp70GZhaXefXYUbIsY+eO7azqIq0tE0xsauLKSbz3dNod2u0uVRXzhyGESMohYKxSFB0MRAJY8KDQGptkrDlBZgxicrZt346Ipbu6Qqgqjh87wV133c74RP6aatURLhxqBFFPZ3mRbzz8eaaOfAUpDiJVDwmNaDsDWWbBGggGnILxMURt47gPWILaaHxpQEPkRosRjCgqLkVYlCqAesXEpCGSB9R4CDm5BtQvgr7E9MHPMjnRZMtVt8XQuAZE7Fl4A6OnYhi1AgYIISAi9Hpdxospbms+T67P0bBLeDOBNRmbshxro2ebp9JQj+LFxTSfMRgRkA4+OKzJyd0kxkNVdQlVgTEeIxmEWJLoncGLJbRytm6doFsUBOexGJq5MDFe4mWOF5/4LFPHjvDxT/4Y9374O8mbTURsIgu/5i+7xHcy4tIrY31tHV+NTqfDq6++wukT+ymLBZRlVFcQ6UaxaSp0qckBkjxdCgQfyQMmxLD0UJLeaDM1APEojkBFrD3T9F8dluohEmtODSYyAtN3IShBQmIGtkGEorBMHT/E+MRObr71fWR5Hlm4/drjkTp+fQxy6z4EXnj5AH/42c9y8OBBxhpNtk1OYCrHUneNbtHDYMiznM2btzI+vom5uTlK5wjJwjVUEMBLRresEAKinlzAddoslB6bNZncNEmeWzZNTNC4+XqCNywuLPHCi/u5+/23x4YhqeZ0JL83Rsr4pCQNdd4hIY4fj6Ku4vl9X2Pq8AP49mnEW0RyRDyqYCSnMhVGAtZUGFEykTgWfYyKqCgqARtqk8kSRCPD2ihBPCox3y8KVkE0w4lSqQfjscaTCTRFsMxjuk+x74kxPvhdf4vNW7bRn6Hrqo7aVq//vUIfCUWTY1N/HkBEWFlZ5ui+LzJePc6W8ByNDLzdjW04GhJo0gIDzpY4nUykWo8JHiVyc6zNUI15YO9LoEsVApVUyFiOoYmSYb2Q2ZKGeHwoKbUiqxym6GG84HxAjUVzg1QwZtu0jz/OF/+wjQvCt33Hd9JojfXLaDU5ZNHx2hg5b5BnXNuuMb8jCt1OhxPH9jM7fRBXnoyesPYGXbQSAUuERK6S6ClrDBD3byow6M4TfyqYiqihY5gjw6YiciVIuhbxEGzKNcUQWRiaUEQFiyGE5C/7FayUVD3lyKEGY+MTXH3dTRibpenbxbyxXJ5p+csD0dtxKPteOMhnfuPfcujgy+QGdm7bwppzLC4vsFJ2EGMILlrF27fvZPfVe8iaLU6ePE5RlEDAI2hVoZq8pvRMBInUocoVWFVwOfmm7Vx/6108/dQz3HLbjWzZsZ39+19hYnyS9915C0ig3/hjhNdFIPXVVUACHgUMNqWDgii+6HLkwCO8/Nx/QrvHkLILLjJbvaQSRIlnMpBCxB5VS9Dogdmk8I36RLYyiLpI6gIIsTqCEOuWrTGYXAi+wiA0QpxwTZplM2NoGgc6Q6b389LDyp47fpTrb70DkUCI7SawZEgwMRV9JacvtDZOhCBxBgfFqgHfpT3zDFuXv8ZEa46s4RAVWplgcxsrUyQjuFghg2QgJYiJHB0iuRJpAZEhH5wQXI+qrDBqMFmD3OR4NXgVyA2owTml4bv4TAibDUW3QquY1mohuKxAsgpjPb3FZ3jgj/8vfHeB7/ieH6HRbKU/LDZ/iQVzZkOkfMk1RZwgJSXOo6UVvOfUySmmp49SFouoVrFxx7DtJYIRg0lEqZjXoU+cinmkQUeswXGQ1HXcp/6cLsH0GxHEGsb+FzIsDulbyzGH5VMrxpKga6ysnOTokf1s33UVY+ObSP44o4n8jRDltrbW5Stf/iqvHnyFZtZgvJmhQVlYWmR5bQWvnkYzRjcCnm63Q7vdZmJigt279zAzc5pudy01eQnJCCJN8CmXFXzy2oSy7HL02BFuvvF2xCj797/IoYPK+FiTHVu3ctstN9JsjZb6Pl+cSTg2yQ8OMY2kimhg9tRhHnvgc/i1BWzZg9KBzxABjyMzgk9VESZEXofBUjOcY/vTOLh1eCzCoKteahxSK1tV8HWZpInELGNiXlJrS7uOtoU2Wh3k6MEH2Xv9zWSNHBGNnZ36BJDaW7oyx3UgDEL+xHqomM1tErpdutNfZ9v4Ko3cIVgya8gyG5W2qZ2e2FxJRPAh9X3ARg7Q0PxrxEQjTSDPMlwQgq8JdlnsmGggywyNRhPnHK7y+BC7M0pm8D4+E5PahOCoSsW4Lmvzx3nwK/+ZrDHJe7/lPnbsvgoRS1DHIKx56e/vpZ9xalazSrSwgmd+YYZTpw7TK+ZRWSVoiZLqgWXg5YqYFOc3/XByTMDb/nYjNvaa7u9TK8YMiKUQagxIhkiGMQ2MaWBNC2szrLXrGHZ1H9xYFhVTHQ7BpxmiTWCe0zMHOHniCBoSiUxHyvh1IXFSDQgzp2c48OJ+qBxNsTRtTtEraHe6qLGExJAfazVp5hm+KlldXqYsKnbt3MPmTduABsET5auSGPQx+qEEgjpCqNBQ4Yoey/OzfPXLn2Pq2CGmTx1jfm6WE8dP8txz+1lcXEmRl5H8zgc1aVKFPrNZkl8J0F6e5/E//1382nGsa2NcgMog3kKIhLxAUrJIkp+kvC2xSiIIsaW8gFjURO+sZuAHVYKmdJJCUMEr8T1CGAqvGmMwdkDcqds4Ns0BsuIJjr38ZEqJWUwax3X3ptda+1cOhFhtEhnsHgku+VSetdMvspmXabaWsHlJo9nAZhkYxeYWYwUxikmecmZNbLSUeDy1oTSQSzSCjDEYIxgD1irWxv+HUOJ9ESMlJm43RtFQYTMYH2vQbBqsDeS50mwKeQOs9JByns7Mfj7/B5/ha3/2x3hfEZLxZ0J8ht/qaoYXgg0x/+tsrqqyurrI0SMHabdn0dCOL+oE+o4AACAASURBVGKoUXEx72dSuZIxSckmpZsULzJQyElb9hVxRK2skwKWDGNi6YORHCMNjOSIyRAzUOxiBg+DSJppUo/qeH5F6aIsUhSnOTF1gLXVpcTgHoU43wg1q311ZYW11VVEFfWOsuhRFD16RYFXpdloxlJy76nKgl6vS7fb4ZZbb+Gnfuqn+MhHPoZqXdYSQ2d9TyqJoNHImJwcp9XKyUTotdssLszTaS+zY/sWPvzh+7h27/UsL61x/Ng0Ply5k+6bh6Y0Usqrpt7vQRTVipeefpiVmRcw1Rx5KLFOyTSLeWBfB35NGjMmRrhCzCx5F3DOo16jMk69AercdF2bHlKbTa+SwtqC1iTPfqFDJAn1iUIJxhgyU9GSRTaZo8wef4T26nwkFdWcEWoFceVCVFFcNLI0KuXKW6ZeepTFw39CM1sga1SxKYttAlmMOGIJmqNkqdFKZNWbvgIe9PqvDTsRg80sxlp8CDhXggSMBWMCeUPIcxMVtFEauaHZsAiB4EpM2tZqWrIcmk3DxLhlvCnkYRUppgmrR3n2ia/yxKN/QXBlfG5lUB57qXGJw9QpSZ7mubKqOHVyipWVWaBAtZvIWC6RtEI/DB3bmEUIJipgYlMA1YBKHDiqkrLRNdlLkpeayp3qkDO1YreEEPreF0QLLnpGdTewAdEIBSsNRAxVn8Xdw/tl5mYOMX3yRiYntiYP+1Ld13cGzmDPax2khlazSZYZSlcwYRuR5OEqnKtoZBmGDOccvowLgRgxlGWP/S++QLPR4tSp6RjmGmJoW1MTsMBaS2Zz8qyBtZZmYxObN2/j2LFjFD72Jt+1aye33Pxenn/uBY6fmOauD9zGmM3PaiFfLqUQlw3qiC+hz+eQ1HlpZWmaw88/hPFLiBbgPEJGVQU0KMF4rJHoIQMmGbx4EB8jZ2IVEYu1SRF7BRvS6mow5JuTgp7RMBBBjaIqkdB1xgICMbQdjWqLNWDVkOkKXfcsRw8/yh13fxKTNdb9qVeoQlaSo6Oxr7gIqhbXnmPp8Je4bccJTEMwoYHNxhFysqYBKXEeVC2mbt6CoK6M/BuFPI8RSTGRHxCfH0NM/xusjdExlYBqbPZijUnaS8ms4K2Q55aJ8RZQEFyFySyZBdTRyHPCWIYvlaobMK6g0iVWT+/n93/rX5IZy4c+/FGsydkQTcyG5Izj4xx8YGlhnsWFGYIvQEuoGdG1Iqb2RGVAoxeT8lLSv2mDmrEYshDNItkr1TDHHIckK7m+0YMmAWIktehj8DsKhH635PhSiXlmbcZj6OF9DJkIaxS9aU5Ovcw1V9/Mpi3b0+9ckUP3DJyzdZ5Gdbzn6j3c+p7bWFxdJB9vgLo4rYYAzuPU4FzAq4/yzWI50/Tpk0x/+TTOeRCPmOi/ZDan0RgDhV7RxXsfJ391tFoZIjkfuOc+tm7fxXPP72NpeYkHHnqQm258DzNzs5Suzfs/eDs33XANdqR4zwMxIqGJDCmYGKkInq/f/wV6y69AVeBdifeKCRaX4saioI64EIAxYBRjpZ/Xtbml7qInEMlZZhAu7ivUdCXWGEIKcdarsyX7IHFBIrHPGIGQvG6rZKrkMgYozfwkveVnwX8EzbYntklNU7tyn4cKQciwGmL/6M4qK698jZt2nCbPSyBPkfxaoYVEz8lB65WcqigDBO+I0clEmBWTYWLj8Jjg0ECW5VH5+hgijykJEHyiWcXGH5k1NPKM0IpLaXa7BapKo5Ez5hXvs5iiahpMFr38jIIJabO6fJQv/MG/Z9PmLdx+1wdRSeVyl/j+XnJlXKdeiqLH3Ow0ve4K0SuOjOc4QfvEoq4VclK6UoezYkhq4DXXRB1JROp6ZaWaQS01fwsZrM8TrVwx8d1QGVKISZFoEPTbdw06mpKWgquX3dPgUW2jmrO4cJzZ01OMT26KOZMrePCux9k8SlVFjGXLtm3s2L0T53qoh7zRoOg5yl4R9wv9ZE6Utwlp5a2KoIE8M4y1xgCYGN8CWBp5E2sts7MzdLrtuAhYDkXpOHZsive//wMsryxx8tQU09OnOD09j6s8W7ZO8uCDD7Pth76fHdu2vuHfMALEMVdncGP1wdLcKU68ug8p5gjeo8GgPiBe06isjd5EmBQDwUcFG5lZkWhlEj0jAEYwmsLhdcPrNDZV0n6pF0FtSFulb4QH1X6I2lhD5RzeBSTLqNL0YvwK2jvI1CtPk02+l73X7wEqVHLYIKbtxkNTd8IMDYZud4Wjz3+Vzd0HaYzNg53Eqsd5H9s/GIeaGHEMCGpMjF5KQH2IPIFgEQteUzRDLYhiJDai9cFRtya2mQH1aAiI1tFKxRrIbSL8GSHLDFmWkeeeoAHE0GjkOCdoyAneML55Ar9WEJySaRevjpljL/DIA19i97XXs2Xbrg3hi2xMzlhheWmRpaVZAt0YntaCoC5R533/lQLK6dbEd33ylpyZCxbJIOWEY/1ijjE5IjblfrP0ituRlNOQxL5N55UU8u6HrdO/opERElTxOlDPcZavEO3QaZ9idvYIVdVjpIhfHwGYmV/i/gcf5bnnX2BufoHl5VXKomKsNU6rNYbz4L2vV72lXss6+IBzLi44HzzWCsZaJsYnmZzcxNjEJB/44L186lM/yF133c1YcwwRQ7fbw3vHkSOvcnxqivHxuOZtp7tKt7tM5XoUvS5PPvENDh86vCFEjnceUpFiSgepxCYQr+x/Ar82hbgu4g14iwaLD9EQDmqigg4x2qVBU644KdoQm38YNdEu9krwyRvu2+pp36SNVTUpgDMTTHWnP9L/PRobkViLV6XygRKHl4AJDludYurQw2zfOgFpLhAN/RTbFQeBPDGpy6rkxIuP0Vx+jE3N09GlM2Btg0Yzx2aeYMpImjMNJGtgm3nscGYyMBaRBj5YQsgQE/PJcd3j5GipjX6vCBibPOfoRce53lL3lI7tJuooKn0Wd1zIJzaSEVGy3NJsZWzeMs6mTePkDQOhoGF6WLfI4/d/jof+/ItUvc6GKMZL7BnHgVMWJfMLs1RVG7SHD22UIhG2NJWopDaZWntDSWHWizikPHJ9w/tLJoqJHm1w1B72cFe7+thBo49U+lBb9f1uXGnw9u3rgTKIbTJNGuyJaa2xYjaENWbnj7K4MMfVezddipt62eNM1uoAM4urfOFLX2XfM8+yML9I1S2xRgmY6Cnv2sux4ydYnJulptH0iVk+elBK9HREA0W3RL1h69YGO7ftZGlphanjU0wdP0Kz1URDRrvdZnllnl5Z8OQ3HkcJZEao1OF9Ras5SahKZk7O0F7rvKYL05W4mtMbQkJKHcVFIAJCr7fKS/seQIsZbKQ0x1C0j7na4OuyoTq/q4An+EicxCeqh1ewsU1l8PUa5fWKtCFNxqY/bwB9hSw1kS/NJ4G6b/3gmbRZRlyus4ojXZXcKiJtKj2NVLOgmyL5SOUKtq/TGtQECMuMVfvZNjZLZkAlQ7RH8BmSOVRKIglrDGPGU7Ay8X8SATfQpdHaRLNlsZkjBBsFJdWAfJccpdiieMA1iuVpBi8B5ypC8CABaxWfKlStjQz6kDrwRcY22DzQaATGWoayELoasJml5SvK3jzPfv0veP/d93LzHXdd8ju8IZ5xr9tjdXkZ53tUvoNSEiiJSi52Y6mbfQwmvuSfnuHB2qSQM6xpRJJO3qLRGKfZGCfLWlhbtz0zkUEtWfKW8xgOSXnjQeCjXyxxBmtaZLCoRN3FS1PZTMxpRSZw0C4rKzOcPj1DWQwpjysMAzMmflp/D5zzPLnvOR54+BHW1jpURYUvfewlLBabNbnu+pv4+Hd/L81WI7LrNbYy9d73/28lMmM1BKrK0+0ULCyu0mi0uOqqPUxMTFJVFXmekecZExNj7Nq1jbLsMDc/y+rqMt7Hkif1JfiKTrvNrh27ueWmW/rG3uv9bcOfrkjUjXkCkNrwr63O014+Rm664C3iPVo5gvN4H5KHa/Be8E7TSlyxE5d3Ae8U7wJV6fFVIHglpO19GzkM9xCXlK9MijeRMhkKd2udp66NQ0CMkOUZthnXSY7NXnoYLWmYJU6dfCaGVlNZ5FCl5RWHAEjwlEsvs6lxlFbmyEIDq4Gq6uJ8N6aNqNK9HcPYzdhsAmObGNNANSeEHJGM5tgEttGMnbLEpFecj7WWZYiREGMyrI3VL4OyUYnETh/rg41N7GDRVAETnTTvXexbIQERjzEVjczTbORgLE6VZg5NCo7uf54nH3sMX4XkEF66+3vJlbH3gfm5aareEkY7EHoQqpgT1JgD1ETKiLayRlZkqilO67PEpaoldcaSPNUJT5Blm8myLWSNrWTNrUhjCybbjLWbsXYTxkxgZQwrTSwNjGYY8thgPlljdXef2JatfsVcNuIQrYCKWAttqZduFBR8QdmbZW72EL3eSvKor+zJWrU2cOIEWAFHp2d57NEnaa910RDwocLjKH1F4T1F5Smqkttvv53rb7iJgI0TogyYshjw6qhcSeVc/xlaW11g375v8PLBF8hbloltW7HNMSa2bGf3Ndfx7R/9Pm69/S5yK+Arik6JK8FXSrezhrFw5wfez+6r9yQ9WxtdZ5PklS3bCBupNcaBKkbhwDOPkJXLBN+gR0HPKw6D01gHrImkEwSCGNAM9VkkTQbFVR5XBtRHoo+vJOWcBXGGEGKvgMjqrRd6iWFuqeOmpCZBSXnXJVTBa/TSQ4xqWXG0RGlqBr6BlxYinnEzTXfmOVZOnybg8VL129dfaVCUXjCsHnkS9+oXsGEWzRyZ7ZCFitwYTKMiGPBkqGkRMiGYHtgMZCtOm2iWQWMCs2kXTGyD5i6CuZogW8GMgTTwYtFGRkEeI48aFa7zEKSByjiBMSCnKgu6naVUmhQwyXEyNvJKEKLh52OaQyRDaRLIsVlgvFXRMF1y8Rip8OUCX/+Lz/Lq/mdQoLyE9/iSE7iKXpflpQW8Lwi+QoOLi8UHh2hixWpdVxytn+FyglhjHEMdmrxjk5h4kPVzvqDktoEYF8kEqXAxEC2eaFW7RAZIzA0MdZO3mvNF3Uu7P+fqGa/oOUcLTKPE8a7L6sosS0tzTGzejB0qy7pikfhxCqytdnngwbhEoneesuildooxF1x0e3TabY4fPUZ7tU2v14sDrI6SJPkaIzQaeSwjA6oyLhLgXEVQOPDyfl59tREzD0aQzZsxVnj22WdZWV5h86ZJup1VemVcltFYw8T4BNt27qLd6bK8skZr52bqrnF6xpM4wjCGTZLO6gonjh3CpraVvvZMB45qPw2kGrlVIfElTc2OTieMxMyUPVLQEPtQm+QxxXzhmbWhdXppsBSi9q+xDl/3U1cpjG1EyKwlYAiaomFa4XpLdNrzjHP1YB64Uh+Bos3c8W9ytV1E8agEgq8g8TUkz6OSE4fYJkorpi00Rg6zfBxw+CqQ2cR493HeNBIwOFCHsQomrlON5gSNLGoxibeTopcaoNXcQmabeF/hnIsNYjyot6BZfy0aY8EHj/eRsOd91AOZNXgDzoVY9yyO+dnj7Pvm41x3+53QbF2y23vJlfHK6hLtzvJQl63UOi9RLurq3lgHTMox1JoxDcxUYzxo4JHH5H4ibNWhRa8BEQfiUgjMI+pjWzVxaTJw/eYTKvUEkXjTIqk/9cCzkzQpR+XOYJYQxUhA8Ggo6LQXWJg/xTXX3hhzXlcwap5tPZGdnplj375nWF5coOx2MJoTmfRp5GhgdWWJTrvD1PHjZDawc/vWJJuY+4mt8UBMZE9mWUan62l3ujjnyfAYEaqi1//txarCWosnlt2M5QbnynhOk9Fs5kxumuDGm26kqAoef+Kb/KXv+jYmJloDEl//b+I1765c9AuPEISlxRmWFk6QE8eIhNQJLeWO+4ncOikUU86pi6kZhOv6Slj6irueCoLG3HHsfhpi9yUdKGZjBvsmdmYat0kxDzGx+wa/IWWwoV7uEdYwsozRwJXcZ16A04cfZ5yj5NlabF2qHjUGk2VIZlHTpLZ/xOaoz/EqGKv4UKIhlpNmrRbqkyyMB+vTqk+AV4LzaCD2F0hpj0jsDanDoUN9D1WH9wHvbIysOU/wgvoQeQWpGx+akos+4HyFV48LgnOeykV6UfCxbj2znrX2Ak889gCf+OEfZ6zZvGT3+JI3/eh2VwkhljKFUA1KmKQuL0qDIzGZTd1JS1OTDupOLZFFHXMJDYxpYk0jvc8iWcN7wKGU0WMNDgkOJHaJCQImOLw6BjmndWFHUeoVI/rf9HlfKa8cY2CJhFIh2sOXK6wszdDrtZmcOLM85kqADLkQ0Y5K6xUrzMzNc+rUNJ3OGo08o+z10OBiB/EQcFWFeE/hC7I8J2vkaXKNC3UYEYIxaSlMQIWJiU1ctXc3L724n6rsEVxsX6qJjCfG4NRTVQaPIMFhfFxCzdhYLgdCp9vj1KlT7NxzLS+8dIB2u80nvvejbN++ua8k+oxaAe0roSsZkozoyKburswQyiVEqzjphsiUDjVbup+3jceFEKicQi6YkJa1k9TOeOjO1sQsE6DeKYTUK95KP0+Y9iYxPvsyqrfCoGSqz0kRE5dgRJOnbJPxtcrM6RfYecO3YshISeeLfUMvO3jnYOUgk2Yaa7qotZhkHQUrCHn0hAXAYmQCyXKEEB0ka3GuIqY0JnDawwiYTNCsgSuFoBnGWjR5z5FsG9NDwcUeAqgn+AJVh/MFRVniQ5wXqmAJweO0xHtwPnEHgqdygbIKOBeoSsU5gw/Re/beR3KgKrmxZMbRWV2gKrqMs+2S3eNLqoxVlbXVFVwVrRoNg8UgjNQ9pAedk+pjYnfJ2vquW9xFqnukuzfI8ybWNLE2ljL5EK0jq3HVnhACQgUIktqeWVUwyfJSjd528nrrJiL966jf1JZf4goo9GsikZq53UP9CsvL06yuLjM5fuUp47NCwDllcXEZazO2bdtCe3WVbreNdxXGxm5osUWe7ZcrOVem3BFkNi5EHhm5MVRpreG6627gOz72fay1exw68DISPPUqX6DgI+s2aCTo5plgxDKxaRPjk1vo9EqWlxYRqZidnePam27juutv5NDhQ1x99R6+/cP30GycWWM6yhYPMIheeXwxj/Er4EtCJYl0JdD3SmPpEyqx+xYSy5HqFpgaWRqaReM7hBBXZLLxN0LwiAreaOrOlTgENuau47XEBSpCqDtv6SD1RApXB8WY1P8aQSU5BaTySVVEVmmvHY29mKG2EK44aPBI9xWazaUURYhNeYJ4Io8nB3JUc4xpgRnD1GRb28J7wWRxjjUyFlNLRpEsi/nmchxcF1+sAj0sFSE4VMs4joklbhp8nwRY9JTSNREZp6wU7xyV71A5j/cVReFwDnwIkQxYQFFAWWZUhcVV8bn02ks56UBmM6zC3OmTPPrQ1/jUj/7kJbvHl1QZh6B02muRpFWvkJHKG/oNPTRDxZ1xXF3Cr3XeUSESreoa48h0hJi7rWtSY9hJUG+T9xOXYVRr44OkaRURGRQ4GbF4X7u+yUQXiUyTPk2rLpFIuS2JXbxQwZiY+1DXprM2z+rKEldfdcMlusOXJ4YXIXdlydEjR/pNPFbWlinLHpk1jI9PpChDZMt3Oh1cqMA5QvDJIw6JHS94H4v6jcmpSs+JEycoigprDeriijAxckH0zD39iAsaw1Rl6cgd7L7qGrxTiu4aNstYWlxkbm6eldU1Tp08zfLyCrt3ba3dug28m5cjBgxn7yr2P/sE1nfwlSe4tNzpGV6u9isIh3OwdXclM8Sm7Zcz1TXFIdGZrel7t/30Vb/srKZN9gug+jnimoJn0obaS4/2uY8doExqDCSKaofgljl6+CA33fotXKkmmEhgstkmA7wagnYx0WSKilnzGBqWDIzDh+XkNDWwkhbnoRnruuml6TUuZVsUFaKC0bi+NVphbaDy1aD3Uuo7ob7CVY7KCc5NQJjE+QlcBUErfFjDOUOvt0ZRRGM8aEnwBaFSXJFT9gzO58SFKEpUC3pFQdZoxpasCu2VJV45uP+MstiLjUvuGVeuXm+2LmGqc0X0lXLAn3FMvVTaUNAzTe6DtneOmPu1FjRRKGsWb03qCik3LCJphRiSxjaRSZ2+NybVsGoMk/Rd4bigKf2ZJzFSYrCtZvkGEI/6Hr3eEt3ucmJtXmHQ/u3se0QCtNsdDh88iBGhrHo4VyFGGJ+coJk3aHfatJot8jxneWUF5+Lyeo1Gg5CUp0idv4/33DnP6dMznJy9n7nZ6UTZGeQw476WLMsiW0gMrixQtRRFxd5tO7j9jjtxZcXxo2067TavHD7E0SNTtJpNbrrhmvQ80P87RhggMjyUIMLM9AkW56YwoUxb4xjq53i1XvAhKsug9cqlKY0RNK68SKy8qHvyxBTGQJkLSqiX47MD5V2HpiUtjhqVcZwvLEPP5CChHGHSHCQmkkEFNFQIiqWi6KwNDIgrEEWvTaZrqFicGqzxiJrYDc17TJYl5ZtFcq4UmCxGLb33aOL4BLV4KQnO0mi0MJnBkmrOxYM2YvrSK0KO+ICEMuaLncM7j/po5IkagoPKBVwIOO9xHgpnKcoWITTIrSHoMupK8IDPKEsIISNvNGi0csZVqVxcYtV5jX6+ETIJ2EvY5eXS5oxV8VUJ6lB16eEfojUCAzKIpkEVFV8/N5v27Rf2q48ej0a2bai9WeiTsWKIMxU2mJjUD5pCZ3Xou15Mok8uGayBDHXemtTcfHCtselAFg0LTwypGEWpCL7L4sIMvW7nIt/YyxGvnbZCgJWlZWZOn6Yo41JnkWxnGB+boNftURZlNG6SKLyPa6hKij6oS+Q5IbZWNJZer8vM7Ewsm/EuRV0CJrN9zoExJg6+RpMsb9DtrFH1CvLM0mg08QF8gGazSVF0Ys0pPXzZZHK8xZYtk2c6xFI/pcPP7ZUL1ViLe/LkCXBdMgmpe7Ah4NKqR7XPSn+4B2Jjn5qkFYbTRcTohzUCRtIaxJEvQopEqUZzedBbHqKnHAkKwehQv+PoZZvUKKTmgsTr18gh0eitaVqsxmCxYiC4IQfgykNwBRIKQlpBD5+aLCEp4lghZMmTbcbcLhXGBLJsgkCTYDIwGXnWwrRiH/AQCtQqVdlBPLHUNJvEUyAhAx8QQuIXDa9TUOB9l8ovouSoepyrKCuPc57/v703+7Lkus78fvuciLhDjpU1F6oKVYWhUJhBAiQoUhTBWRQlki2J6m7LTdtckpeX/eI3/Rteth+sB3vpwb3aMlez1avb1kRLHFoTB3ECSZAASaAwFVBzZea9EXHO2X7YJ+LeAkASbAFZAPNurEROlXeIHefss/f+9vclKpwMjd0rbNkeIAnVRIiJlDwFDl8MKcrAaDSmCS2TJiJ4PIkrF17gysWLO3aNX1UwFpEfA9ews0VQ1QdFZAP4v4ATwI+BT6rqpZ/2OFY6VsRFYmwMtOO0V1nqgqZmCPv8IZY+KEOnc6wZeGXJqqJYUOxGn7rmvS3ilIOxJwQxEgE15ZGk1quWvFhtrCFz7HaaqpAR2V2juAvW5FI5qESbiVY1/dwwZXv7Gm3bvipnvBHstfL19Y+ZKwgiRuQfGq5eucranhUGVUWKibIoudZuWR84KHWs0ai2EaI0TWMLyls2nFLKvP2JkNqMwFRSNLER8cJgMGQwsNGmtmkpywEbezbwZUlsG8K0oeM5v3L5MiFanyqExu6q1KKFcOTQAaqqoBtx6m7MfrY8f/dmstfWz5Z/Wu4JHuvHppBLzaKzSlS/eXf88fn8m3EaNuJkYBrfVaK6Z+lInPLB2JDWOsuy06wE3XHVp2R7jsuZd1exmWW5+TlcyNm5oXGTS9jExSBn9zH3i3enn0unuBShtKkHiVg7KRVAIhTbFAzQcA3vR4goUWtIU0KziRsoIhWuKPP8jGa+cjtsl36IRgMNSIqGiCZrUYtDRYkpkqIBfwuXKH1N8i0hRqAlaiLmw52mMUnHJBVCmuKKFucjOCgKR90EmtAwkDHjpRVC29LEaKhstRv3G//4Vb77ne+8fs55if08I+yPqOr9qvpg/v4PgM+p6m3A5/L3P9VCaImhsaxY1OTS6AKfXfo+6+3+aC5zvg5trbn/qx3tpeZs196WiaYVdorO5auOc7p/62pqT5qMfk3nmF2u/6BHgeZXMvveatMYw5fpJHd9q6SBpt42JOKby/7Jvn4lE4G9G3s4eeIE0+0tNq9eY1ANKMvMktbfAjZ/iCreeZNXy/dBNRgwGo1yz8+y5KSBmAKa2kwgMzf2VA04ePgINx07xmAwoKoGtE3D1tamjbKlyPnzL/KjH/+Ya9eu0jRTQmiIsckn6cA3v/l1Hv/BD4mv2G54U/cQXxM/S1cazllp5T2FdGXJLhu2knTs1k0H7sl+tYOzsWYpGXlNbiklmwONcca+Zoxac3/zsg/y42rOhPK+AaBqeJEuIuexJ1vLmU9R7PBtExwWcJQ0K3O/ueyf7GdHwiclMUWkwRm7B04rvC/Ah8yK15DiJujEkh9xwIS6uZgTKCFpRJuruLCFC1Oop7g24gP4NkFTk6bXIGzmHoUjSSJQE+J2zsIVr44ST5E8VfIMVDApj4ioTc0gDa5sEd/gy5bBKDEYJcQHQmxpY6SshjhfGNArWbBPqaWut3c0kfqn8Ml8DPij/PUfAR//WX9goB37OmGbqKYG1RYIiBX1cZr6eT83R+KhGvsAbGjsPKOYNYxTHkTvZk8czpi1OqkJFSP70G4m2IhGRDvRtY60vgBKW4RZqLybcbMUL1gWnAlCFI9qZXPODBGGiCQ8m4T2GnWq/wmX+Q1hP7evr0sgtNvsEksrY97xS2+nGhZsX91isrUNKeKd4gsrJbapzYxOZPSG5LlD81JVFFTlwKjEk+YzfyKF1gA/WQAtJFN0uv32M9x911sZDFZ57rnnuXrpEhpsY1ARrl65yKULzzOdbNK2hj0oxDEcjNi38Wy/dgAAIABJREFU7yhPPXuFz/7Hv+Lscxf795GjTF81+QWxn9/P6EywIX8fJBrfQhGJRYtPDp/AK7nSYYfc1F2/JIh6XCr6PqBGITSJEJQYsPnRfGhOOk+XKEjqMuVuEiLl7LfrQwtRDdcR80dSEyEw3mQyGtj60Mb4Z6CiggLvtnHOvpdfDAqun9vP1rjzJJdI2iDJqpPBB1RLfBwBlY07KSBjkqzQMkaLFWv7pIg0NbL9LEyu4qaXcZMXYOssaessqblAZELI4F4Jik+KpICkaOucAZLJRMQDXlGvaFnAoMR5h1elZJuC5yE+g9MaSRXiSooCqiIxLANOJ2g7RWONcwrqSKEkth5HkcWFdi4Yv9qesQJ/Lpaa/m+q+ofAQVV9Lv/+eeDgz3wQ1b7W1Isw5DnjjtLOft/NlLnrNnXFTi4CxuCS01PVgOII0Y7noiC+6ynZrJkJU8fc+4n5OYOd0jRl5G2Hw86lVebLaPPvpDsc5H+RwV9GatCNaAVMOMICwpvIXhNfw0sKerk6URSOX/qld/Ctb3+HL/z1l1heHtOGlq3tLQbDCrcpxBhNKk9mfX9UbS22NSl2JAEuZ0f5kJQl0yD3AGNkOp2wtbXF4QN78EXB9vYW3qn1n7HMuJ5u9aVv5xwr4xWWl5ZZX9/HyVN3cO9bHuLc+XN853vf5/DBPQxLP/fe3pypEq+hn+3RXJ/t4gS8Aavozq+YT5yTHjXd/bx7MfRYgazKFGc9eS9WcrYqt3RdK6MBSIpEzWNS9jhZwJiOmUsVYjLJvTT3jBkPbNmy5LaIKyBzUauW9hi8+UrU2V4jP5uEYkoJT0kKA7uOvrXkNVUkDbnn3lhVgQGkQDEYmVDI5CKqUwqviCRis0lortkBTIfGfOYbVLdRaYmZyyG0DaE1YkrvirmqhiIFuASBPBlTWBk6pUAba1RdZu0iuy9RllBVGf+TttneMq1tzX0V64K8hKltB+zVBuN3qeozInIA+AsR+d78L1VVRV4ZdiYivw/8PsChgwdm97OQe8SW0zrmAlavLZxy6TiXq3S2jFQdSVq7eNrxSHcB3QKwo7DSVgookZSMbi2lJgdwy8SzPhspA396lp5OpST/rOtz2caSO17zfu52CO2CQbK+yJsrGP9n+Xrez8ePH3/5o8oso9jY2MOnP/1p1tf28td//VdMtq6RJpGqqijLgum0tr5dirkqEvvN3FDNKYsS2PWeXd/u1GQVixAjNPDVr34ZL99ge7KJEhkMx0ynU9q2IQXbYEyBXqmGY7yv8OWAum35/uM/YLi8xtLqMt/4xjd4x9vuZVjO1Li6hPBNuE2/Jmu69/XcwSlqN51gamalLzvpABNv6IKkYlko9DP7mls+/aSFQopqh+yYqWeDEDM8DCc5cAtpLmm1innmfhML2Cq5AubUWhSSAWT5bXocuBKkQhnayKSMUCrjxpeu4P6m8vZr4uebDoytEpgKVEeksIpKg8ZLhFSDCL4orVrFVQtl7YAkE2iuGVd0p1cdBHUTqzRKhfPLeLeEaoO4Ldr6Km1qre/cdsRNtjd7X/RrXKRb6yl/bz/zBRTqUUnEpFmYJNohXxLOC75IFGUkxUBTK22rxNhackanLJZom51jp35VNRdVfSZ/fgH4LPA24JyIHAbIn1/4CX/7h6r6oKo+uL6+1rXuLQhnpHOvspIiSbuj9NzMYJfd9v2gZM38VJPilBQbK3enlpQaQmho2ylNOyHEKTFNCbEmxYaUmpyt5mCclTzEJcSZApMS7PdZKUhzH6vL7ujYeXo0NnRBYZZBd0QG8eUX5Q1s/7m+nvfz/v37eVnxtuuv5+v13PMv8PQzz9DGQNu2NE3D5uam8cumOPN3NBrTpLaYYoy0bWv4g5whzzIqA2P1dKYYELCebrO5dYXYTlFNVMOK8fIYUGMFym2R8XjMaDzGlwOO3XyK++9/gOl0m+9851GeffosV6/Ojan1+/H8PfDmsddqTe/bv3/malXKosT5ioTLuBCArHfsumCshqKXuSNsDoxRlSj22TxrovNWQBPQgpQkE4TYBEN/Bk9Wts7bi1WrmAE8O53jbvY4Zd/ZbSlZMchkIMG4lVMqiakg5emKnxC33rD2Wvl579rAOMZjQQhCiImmCVnaUKCN0F5F01U0THEh4MMU116C6QW0vorWWxC2kLSJpGtoChTFMsVwzSqXTEntFrFtbd0TMieFcVuLJNu/NeaEbdaWsGx2llDhNJPq2e87mcUuUXI+4aSFNEVjSzttaJtECBAyb3VoW77y5X/YET/BqwjGIrIkIivd18AHgW8D/x74VP5nnwL+5NU8oTFqab8325nGqCpNRq1TU+my4+s/uiqYEYW3qHYftolrtAw4xoYYawMUZGBPSg0x1TYcHus8BhN7h17/OlMOCN3HHOhjrmw9B/Gaq2mTx2k6Csg3R2b8Wvv6lU3Z3m74u7/7e65cuUrTBprWaFEVKy0bG1uXLWkWEplJmtnIU85mfAbNZVUnzaC8viFJrqhk5RdVZWt7QtNGFMksQVAWBePhmDtO38nJk7dy6dI1nnzqLNtbm1w4/zyXLrzI/j17KF/CM/5mDMWvpZ+7DLS7ELfedhvFYAl8aSIOWGlYnLUBfL7ghssRc3KuOs+CZb+MZowD6qwFlLoxKOaqJNoH5C7r7gBhzD2WAbWkb3H38V06fXNPTPl+Uzt0J3GoFi87W74Z7LX0s2Y8jQQT2FF/DfG1AS8ZWB0zbBHSZWPImiZcbHHtBGm38e02Emq0nZDiJVybKBJoqmnqy8S4SYpbxPYaEieQWkKTM9R8QNcUCSHYHjF3mANmSVO+h1Ky/TrEmANxBgqqHba68TnUuKnrSWK6rcRQYDKPhs4/++TZ19QnP81eTZn6IPDZjHosgH+tqn8qIl8G/lhEPg08CXzyZz+UXRBxDpdmGsKzX+fFhZ1wZ5XNec7Z/DeqdOg8dDYapRqRNEfCkchZbs66NebMuAW1MZg+GKv2I1GzUnXMJy5Tk+rIAmTutc8y905v16gacVZyexPZa+jr6212vYz56uzZs1zd3OyR0tZPnPt3cw7vNKedeJzLCk2pxTlHVVUIBcPhEpvbW2xtb+JzNkaEqJGikCwsYYQTddNmZG7CIRTeZp2LomQ8WqKO8OMnn+WJy+cYViUxRDzKWx+4j/FomLfzHH36GZk3VUh+bf2csxTvhMFoRDVcJRYDxF/L/buE9942OM1BuANhpdl90VXELEvVPuCKNxxIjDayVvpezqGvTqkqREVzCRqwx8iRXgGn0icAxpZn2XDqt2aba05agwMnJsUoUtIPYr25WsevmZ+7dqFLCXUR8VNsoRliHkkQI7E7LIVECoGqEjQlNHajiSWJYC0Hr4a8FmeZaHMN2k0j+UgmdYlm8aBkN4pzLveSZ+Ih3X2Ssr61fW/rO+RDt1VONJ/CbLS1a4G0TaKpldA6ktqhPmX8ibidE/n5mcFYVX8I3PcKP78AvO/nfUKHJ6qdtMR5iLlnJF2cyxc4f55JItIDMfIryN2bjmkr89nGSOx6zt1JWwOasoxiDtizQNwF6tnjxFwa7f6tlUlif4LvS2D9bBPY7HP3RvJnMqvXmwSB+Vr7+joTmEfcqia8KxiNlhC5SL4jZlWIGCm8tzlvo3Wg8BWDwYilpTHXrl2hrmtUYX19D+95z3up28Rn/u3/jeoUzQFAU6KpG7tbMr95DLOsyd6fnazbNrC9PWVpdZ19e/ehcZvQTCi95+iRwzxw7z0UhcvlroxleJPtzvDa+7kjsxLUCHD8iCgFRVUgUYkKJLGxpmB9W5xD4+wobgcwKwWnfL6Jmqzi6H0ehLBDbnTRwGGAzQXnwrOApDTTnn+FdDZ1WAPncpbkTFtZBacO55zBB8Q47V2W8VP1iHreTL5+Lf2c1JFIOIlENcEMEUUkolLbQStiVQSx4B2CA19T+AEkT2imQCCpUgrgh4gv8YVSN9dIbQ1BcVLiRWnZAi3mrvis6hjalH0ps6maTNyTkuRRuI44xippqsZpb60wiy9tjDQBQgIVZ+NNUQhJ8UXJHXfe9U9xwc9lO8rA5cQZB6krkOTpaD06OkztSN7tp5ADpPPdxscM6ZEzYVvacRa4Uct+OyCPqnGTpg5IZXPNqtFgPpnIw8rPlgGnFPNryeforg+BlS4sEbDTXNdL7g4JVmQzsIfzBd6XedZut5m85GulI3sYDAuOHz9GXScuXhIG1YDptM2C7+aLajBgOBzkHnGDqjGd+aKkGgwpptvUTY04IaTAZDLl4JFjDIcjJpOpnYVSh8Xten1ZPSjjEqR/bebX7e1tzj79JIePKAcO7OPkiQN8/3vfZTRYofCezc1N1tbHL9mPde497nazUm85XINiTJza2lUFopjMobdT9xz51SxkGkrPlpo3pLx2HJZ53lTFUNEuYnzwknmnnev9aUIj9siGppacMdnhOSV6UpAQjaHLixDVI84Z8Ec9hR8TGaAyRvwgHxZ241qGhCf6kqgBkRFQ5EmGKeInKAOEgVUSNaI6Rqlo4oSgLY4K58BJjdeCxARigOiItZF2WDmxsHYSWSQiQUfqoDnqahLTOI6x53vQaJlxjBakQ0zEJH32a0m2yy3MQEgWgENUmmgEzAn7PkQDIaoKp8/8ggbjojS9YQ32RgVrJsmMnBrU+G4cnb4t1ivKv+sZj2Sm8NSNTKVMsQldZp1ngbWxnoMhPGzmrSca6f4ekLbPlG1WUfuboFvU5KzeTn8dklfm+hSaDwJGAlIUFW6X6xl317kr9VVlyalTJ/j2tx9nsj1hNBqTohHC4K3ENBgM8N7TNDYmkZIQCTRNw+XLl9mebBnyMUJdT/nmt76Jf+wH1k5w+cyWx58kt5eSGrpSSH05VJzJdSpKTIErVy6RVBlUQ+p2m+2tbW46tMpkUvPcc+c4fGRf7nW+BMtwQ6/vDba+TG8BcTjaQzlcIdYVEluch5QiRWmBUpOjjZCikeF0euIpmXShrcmMnLbqpwnLZ3IOY9tKuOgybt56z67wuapiqbX4uZfXWy+EmR8nlzt914LqMuYRCWNxCloRtezv4N1o1XCZRpcYuAtErSm7+1+jYXdSgafGeQt0SZdQRsQwpvBDoMDJNYQaZ0SZpNgYd4AqGpPNgku3f0KMLss0GkFUUkgaCSHN9mjss8kgGhVmCB1mwFklJdlUToyRmLPitlXqRmiCmOiEKlFTxpxYm1N8QTEY7tg13tFgbIw7xlcrMvvoys0zS7lUbTe/nWTpe8gdJaaVs7Tv4abU0WWSS4k5sNIYPWXqTljdAp2BgixgNCRaC+BEurNAX4zO5AL52ehg9Um7EsmMEUiwgUbvy77PuWstH6S6Pp9zwu23386ePV/lueeepa4bqrKiWhrlkaOWlBJ1HWiCoSkdPsuiCU2Tx9U04hw0zZQLF16kiY6kMQ/wpxlLWkrgjAzEiTNqxP7Fdeh8EBdp2imXL58HhaAJ1HPh4iUGgyEXLl6yf3dddrR7N+jeFFucuad3z30P8Q+Xv8n2ZkWSYIFRMDWtTkc45kqWU0gzxr1ODD5owueqsKBE6ehspS+D9trWomgAX9qyT5kkxmcAWXdYmEMhYD1Hl7NrRxIlibcxSTyJISENEDfG+xV8ObB/u0tNXMmkHTMsBPwEj8NpmbdBl0dJa0Rr6wGLCTWgB0g6QuUK4jaBKeiAVBU4V0EADRGoQSCkEmRA4UtipmzryJZUY8/gFkNLiIE2hMywFvsRpraNudycs9yk9n0biSERg5CildHb4AgpEmKkDUrM5DIJx9333sdtp+/YsWu8s0IRAnhPbLpyj2ZicY9KCRjziiZLZToS8o4URLvmci5JW6+v48UNuefYac7OgFmRQMwnqX5xqv2NkYF0GbBt/NoDuOY5b/NrFusvSua11lgAkaQ1QQNJC5IW9vhS4cqS0r050NSvq8mMZ9gJHLvpIB943y8z2brCN75+gXI4oKo8k8kEENrGRhG8E1LyObAm0BbfN++N0jQlpW62LSOKrR3tkjM/9eMMhlGohkOcE2IM1HVNgc91LlvIuCLz11YU3g5qw/GASb2N82SEsPWw8xu7MdfzjWZ2WgWBw8duZePQXVx58QkjhdAJ4kxEIKkp8IhzfXATxbTFyQCbPmvVXPwy1ryoFmzFORMQkJwRdzQerSlH2a2W11xRkELEF9ioFR14zIN6EG+rXEtEhiSpEUwvuU0O55c5fPRu9h2/BSXQsbvtPhNaWSHIgEodEiKxbEgkygjECa14CgdORzjXEjlHCm0GygVgGdUBbZqS2toqW6kDS+V7IdpkRQhTW4+iuW1oazGmQCIRU0MMwfAfMRFiIKRAEyIxYsG2TcRIDsjk0aVIDB7aAmmAtiW0kRA9bXIEdUQVUjHkwNFbOLB3745d4R1tgIg4pKiwOV0PqZMkFEj2fa9bqvPzgTE7rutHxDxnnPu7GrBAnqky6X4XrhuZ6rJiTVbSTtpmNZDm+vJ0D/QyhqZ+EEu67K5vW9Mj+bo+dFJEPN5V4IdUgxFlubNnnjee5VLuHBdxWXje+c4H+fR/86+4+eYTDAdDUkoGrlArVWtMeKHvuTsnlIVnOBxQ+CLXUzJHORG0ySpeuczputlQq8h4X1CUBaPxCh/80Ec5cPCmjPDNgiAJ2hBompqmmZJSZGNjD2vra3jvOHzksIkQ9O9o9rHbrcdzYPf/voO34AZruKrAuxkrWtcWUrRjp+2LTd0heIaQnQXmjrwhhoyQzaIg1je0PnMMidQmYqOkoLmS1ZWdO176TjDCDu6os0woObrxJqE0IJcXIgOGow3G46Ubcl3fKFaUFcv7z1CHIagnaWX9W7U0yEQ1QkY1R1S3EJlQ+AJHQYqBEGsirVEJpwyelUCSlKsZ1sYSAqTW1rLacJsmzbwCNgYbUyCEnBmHLrPNZeYkxGBgv5QgBqVtYgZ0FcRkkoldWTvGmHvFEJLQxsTKxgHufeChHZ2G2eFgLCwvreGktFOpkQ+/7D/Ns4fWlpijygRbvYms6pSQLoimTNRBR9YRetJvTYkeMZL7vF0jP4bWPudZ1m6sKaU5wvlk5bOeVKBDYULOvCIpKBqlf5/IEC9LrK3uY1CNd/Iyv+GtQzWLdyyvruGKAil8D4IzZL30vnBZLKIsywwIMnBdN8rWse/g+gG369DxL2GFYDAYc/jQcY4eOYF3A5xUtMH6yW0baNrA1mSLyWTCpUtXePrpZzh16hRHj96Ek5eG376JsWvNuJzJaGPACSduuRs3WAdvFIZO7DDVl5nz+pIMygop5fnfbjTJAna3DrvRlZ7POrs1hdwjzkPDxnhrPMaaMnuXmthDH3zVDmBGEGO81cbUF9FUkuIySoE6R0wlSX2u1Lnde/ISYcJNNLrPiFlUkCAQhVYqVAocbU6iWlSmGJ1kacmVtCTdJKVNYqrzxEpHOWmVzJhaYmyJqe0To5Rh0poiMcyIf2LM+sUh9YE4Bs1o6UTbxBmiugfcemIQQhRCSjQpEZIjRm9YsgR1jGgxZN/BI7zt4YeJO0jatLNoaudYX9/LxQtPk2KJxg6EBfMbmkrqZwW7xu0Ms+pzlvsS1LWAqOtHYVLOiOk4qa9LabvSdN7Ucwm8p9vsN3LyArayqPHpapZJzF9n1hdTkXG5nyigQwbVBnv3HaEajF6Py/nmNoHt7Zo/+/PP8eKLL+K9w3kbY4vRMPJF4XEuZSKGlLWoTUg8ppDnxgE0Z1E2pkKnmpVs9lXzgk9d26INfP7zn2c6nXDo4GFEhPHSmKIqSCnx7HPPEmOgbRu2Nre5/747+J1P/harK0vs9sD7ipZT27lhQ6rRCkdP3ctT33oMmQYQ21ydk362OGSglXMFIo4Y2/4B8+ozOcXs0z5jVsHH7lCns+paXqeag7IkA+i6wlpMRghhj+OwA3VST0fBae2oIV5WbA9hiCtWKapR92pmTL27zpRjp9/G4xe/zDA8z9hNUFeAeBKBmH1i8NsCfAJaEudJbKFcg2SoZRuBo8fwgMv0k0bokVCcM8lSzYpboQdntYRkfeEQIyFCExIxYMDALC6SuhGnqDRtIiXJAdvRtIagbqJQt0rbChpdnmkfIMNlHnjoYYaDEc6XO3aFd7x+urKyRjVYommuIFJlCjqf99QM8REr+/YSiwIdtd1Loip0nD2al7BqBnN1pctZVt31HZMaR3WHxBPRvpfcBWEz18+jzfezBLHB8Z5AJCDqTT1GHElLymKNtT1HWVs78BLAz8K6a/zCiy/yjW9+kzYGtic1w6GnHJSkSW0ZcS+vZ6fokPtPwJxsnvUWnRM0c9eOR0tsbW0hLtpIU0a8o0IMkabd5tq1C6SUqMoh+/cf4N777uPQocN4X/CFL3yRZ559hhCmCMJbH3iAAwf3Xkc8M9uR9SXf70brDs65DCwKRcnJ297Csz/4Imw/CVIDRuyi3uEiOGfgGpz184WYixizNWj6xjM9YiNTMqZikqHhJesWd1TykkUlDIU9I3dQoCgyEY/kYGyvCqEiREfhhzg3IJIQ1lnfuJm9hw/zEufvSitGS6wcfQfXfvAjhsUPCSo4LXBSE52HOCBpp4DnwdfgXiRp0f9MKBBp+oSnm2SJIeSMGFDtbwPNHNFWpg4ZmJWIKWXUtn10Qbdtc2DO1Q4D/1plI4bU81C3IVmPOAopejSJtcN8xcGjN/Pu936A0WiM6s75feeD8eoq62sbTLYvoKlCtSBlcE9ffrTBxH5W2HWO7MQZpAu8+UL1QTSDvTLwS5Ohok21I/cXNZk6BynPm9pGbd3FudI01zO8SAYNzR5DiLl/YdPuBahHtQAGFNU6Bw7czPraPnRXb9Qzmz/oqCrPnbvApcuXaduWyXRCUpfpKfMcYbKZcGsfmH9jhK7vl4zLEF9Utmk72H/gEI888l7+6q//imfOPkVStUWmeYxJoakneAdlUTGZbHL26Zq6aSjLASFELly8QNu2rK0uUxWeCxcucunSVQ4f3jP3ZvLnhWvp1pzk/i4KSZR9B06wun47m9dewBVTayVgG6T3GPOZONqU+77iDIw5d5+Iy6xd/ZrMaFexQO7EMta8h1v/PwO+kjr7OzXSB6u6iI1AZSnHFMksSwNEKsSPic6jfonEAY6euBu5bjRxt6bGRmu6cuAMl8+eZnPyAiO/iXcR7zUzmXm6iRQ04HJ5WVTz5Ixx+qckfe0jJcPltG1LTMFGEJNVHBFnmXE0vEDbWjC28dF84ErQBqUNVp6OwSYjYpzdD6pCCEoISttCDEJMQtuqBeMOMyAFg/Ey73zPezl95s58P+6c7XjKVpYlBw4dYThcQamAChslmM17alZHMSnFNJfdzvq+YNlzzxfNHDgkA7As401kwds8t9wF4Pk549SDweY/NJdRJGkeNs9D57m/NBM6zw8XHSmWFOUaK2uHOXL0FNVwuDvX7quw6fY2V69cYTqd5lGmKU3T0JWYmzZQNy0hWH9/xjds2U3hK+655wHe/SvvM6UlX1AUJcvLy+zd2GsjZXkxdtq2HTisbRum9ZTJZMLW1jXOnn2Kx5/4Pk899QRXLp8nhG00GeL6a//4FabTCYv+8E+wrnbbVbBUcCTKaombbn4roVrDV0PwhYUyJ0YA4QTn81yFzkqW5NFH6MCR2m+sHbFDz7qUn882VAvU9m9dRtVqzq7szJzU2hkpGTOTgbsKEkN8uQdxSyQpSayxvHoLS8sbQJesd/iD3Wh22Nqzfphjd/8ak/IMTVsRYktLRQoFkZh31UDSmhQdmkaIDnOmatoAivkwhNgH2m5t973gqD2tcAiRpg29v2O0zDbERBuUummp69ZK1PnvQrR+ccwZc10nY9qKQghC00DTWHsr4YlS4AdjTtxyO7/8nvcxHI0NJ7CDFZEbAvNdX9vD2vp+traukNIEcQNSnGDl6jTTMZWEy9SDkrlCtc9+NZ9uISfCdMQcGlMO5JmPOsX5yldPuzlf9I46U4bqelDWB+5GIVLuLXXfd4PlmOh4NESg90uU1V7WNo6wtmfvrK+1sJfd2Bt71ikK3/NGqxpi0nr/3SxwRlhKh8Z2GeDlGA3HHDl6Exsb+1G1oZPt7U2+9KUvcu7cCxkg0lUYs8czKUQMSsT6UK4oSclmlotCGAyKfAiMLC2tAMpoVOXXsVszo59mbkbKI90JP6FScPtdD3H2yb9h8+wVUhNJYmpO3gtlCZIRr50KU1ft6oJxB95UcskyE7okVStTR4hOMzmEz7Qj3bha/pvUTXJ4RArEFTmkOpxUiJrwvGnqDkiuYjQ6yukzD1GUVZ/F7W7X28SLJBhtnCCs38/Vp59mJBHXCBU1vqgRLTBoe0HCaDORZGNsOlPtit1+rWSeeLu43Z5q7IjmpSYDsVIyNa+Qs+A2pL403XFna4o9/aUF3kQbhLYVYnCE6AhRaRtvJe3kSa5AqwFuuMLtdz3AyVtPZ77ynd25dzwYiwhVOebggWNcvPAiW1vbiGwDpc0gWiTOgdVkDUlWrHbCdeNFnb5ozqetEK1kUQfTKraB8Y4svFtJc+hsmANszV36bnQiSQaNMReMuxGpvNCTAU1UhbJcYWn5IIeOnmQ4Huf38Xpf1TennTxxjDvP3MkXX/wi3cw4YujbQVXRNDUxNYQQcM4xGFhADCFkwE3g0Ue/lYE4Np/Y1hOeeeYs29vbPQ6gC/QkMlo3QaO4omBlZYVjx44zGAw4d+4cMdZsbV0jhJrQKnXd8I53vJ31tZWM4F40HV5m8+tKHGjCZQTyYLzE+uG72X7uUcTXQIv4hKjinCJR8QIqYiVIwOgyOxRshxswXzoU9Z4UjQREnY2uuNLlAGzzUhq1p4UPrYH/XFFgdIt5EsLZbLFSEtWBekgDVNZQ3aAcjFHXleA7273eVythMBiMuOW+9/Oj5iLnn/sb1qotBAixpnDkA2smUNEWXIta7RPlAAAay0lEQVTzBZqqLCoR+v04n+EQcQbKCjEflLpZcxtJSip5JCkZW1aXAbdGupSizRG3LdYPDgb6aluhjULbCG0LkzoxrZWmFtpQkPC0IshwzInTd/HJf/kplpbXr/P4TtkOB+Mc7ATW9+zjwIGjPPXUJUIsESkB35cTDalsRAyiihNPzFRcnTQb3XD/fBk7S6BJV4pONsfW9ZtypM89iTkQQX59Hd6n3wwwGkUDEOgsGGM9yxjEgFspUpUFo+EaBw4cZ/+Bw/iiIznfraWtn2bC6uoyD7/9Qb79rW9z9epF2tgiCtWgAkzNaTgcUU9rFJNLNBCXZWKRwKUr52mbgLhO77QlhrbHH9jJPGdJGjFUbcQXBSBMp9tcuHCejY197Nu7j9A2eHG8+OKLxNBy+PA673vvIwyGFb0fF4WOOevSRc3ryQRVSN6uuRPGazezvLqX6dZVC4ihsTJ1UtCIw1jR6IBVSq5U5DE2bJ33qBDtcCTMllZXyYrda5oFdik8zpc4qejEBRDBi80UC1XPp+fdiGpwEHHruV0WUKq5CtfuBWNGaU3YQSODpVVOPvRJnvx7oXn6cyQRfFlRugbvM0guEzAlSUbmkQzcJz5gAhDe2k4pZaR0pG2D6Q3IjGciZIW1rvzco6mD/bxtWtrGkNQpYhzUMdK2iWmjtK03+stambTKtIG2cYQAyQuxdKzt2cv7P/IbHDxyzCYy2Plj1w4H49nbq6qKw0du5vLlC1y80II0qNbENEWSCb6rWD3f2v0t0CJa4rTA5gazLJ5i/KYdMQgmTK2a8mjTHNpmFnfp9SyzWARZmLzbvzuSgJQz4L40TeYujQ4XjGvXFSOK4SHG60e56eZbWV1dn3u3u3cB/zTzItx/393cd9+dfP/7j3Hh0iXqyZThaJnpdEpICaIi3uUBfdMjLrzNHccUSTEgGnHay47gnSMSexk+X5SGyNROuWm24ScXuXzlEpcvX2YwGOKdp6pK9h44hCblEx//GPfccyajuHP2tYuzo5dbLy5Ix1DXi6Y5KCg4c+YexvW7OX/hMqmeZECPHaq9z5gMEaK3g3jM8/wGzjZ+efIYknTr0SkxOVKC0jtSq3hNiGv7NpTxC4NTA+dE7YReFC+FTXNEb3zoajwBw/E+7n3Le5FylXIwsOqcdnnS7vW7+Te3AXKg9Esb3PrQb/J4jFw99w8M0rN4TRRJGJBMYdyVOKckiagEm2iJeUolhRn+JyY7SGXNAmPCjETVXI4OuUydrPQclTZk8Faj1HWkaTWPM0XaJlHXar3hAG3rmNaJOnia1ubaozhkMGZ54wi//a/+O97/kY/jqwGQ+r1/J+3GUENlxOzq2jonbj5NPd3i2rVNvGyjMkG1QrVFqVHavCCsjORcV5bO3MO5D6iZIFqxsnSHlNZcquzGlrsXoGDlrJ6fOhojmNVR7Ge4PCIxrwgSiZkSz6eUN5IBg+FBRss3c/TE3ew/dISicLlfuQjEP8lU4ciRA/zuf/FJ/t8//XO+9e3v8vTTz1KUJaUmdCvhXGmI2mRguY4MZHl5mbIsuXDhAinrEptIQCaRT5ZR+aqiKAoohRACTR1Mkg/LpEKIOEkURdkD8pZXVxgvjbl04SL7921QliWzU5y8whrdvZs0kC/J3OYlzF0mYTwccujk21l/7DEuTM9TMMGmmLwlw4VSSCaR6KQtRfJh2to8opnTPpFR2TG3hW08KSWlyHsB2HaKeJwUqJgCVGgi6rzNsxdqbFDJQ3RIMUD8mL0HTrKycYiIZNzJDFG7g1Mub0BTvLp80OqwAYosHeTU2/85m+dO8NjXPstw8qQxarlEWQQkTcxDKngxpSeNiaCN0WBqIoZAMAH4DKgyYpaQILQhg7W6ESYIQWlapZ5EptNEU0Pb5F6yCnUL9RTqGuoGmjzKVLcWmBOeNkEqKvbuP8rv/Nf/PR/4yG9SDEcwmwn4Rc+MO7OA573jwKGDXNs8zhOPv0jdXEVkxaTS0jYqLR2VjrWMSjs1iVgvWX2uSM34pdM8W9dLK//ardWMjO6gGR1XrRhXNSpWqtAuKzaUXggpl6/FHoOAUFKWSwzHhzhy5AwnT97J0tJKn6Ut7CeboDjnuP32Wzl06CBPPf0sf/mXn+dv//bv8F64KjYX7AqXfZvH1TRx+fJlyrLM2qRdX0+zypO1Hrwv8N5TVQM2NjYofMmPfvRjYmwtQ8osajEmRqOK1dU1o9osCp5/7nlAKauSTke75xN5ybtY2M+2PQdPcuaB9/DlS0/AtW2YTlEpCb4AH5AQKZLNikshuKx/nHKVygGSucadhB6UZ0Hb9oSYW1FeHRHDeiRn1LsSnGXkhf2dDDwRQ+t6StA1VNbYs+8ogskyynU4k/x8wG70ucx9wGzUDIFqvI+Vw2+nOnCZ8MP/QEgTat/gdEJRlLgQKUhU3hnAKrUEZuu50x0WJFcdbZ8NyZDVNl9s0xWhzQjqOlJP1eaGGyW21jOetrDdCpNaqFux32eQYJusxRHUQbnE3sMn+fjvfIoPfORjFIMqPztZRfAXvmc8bxaQi7Li2LGTbG9f5OzZCdMaRBqSFKAD0IipL3XjDh7F2FmsV9sFRzIaen58CfqdFPoM+DqwVhegdfZ1h6K2klnKlGuamaDIm3/Ce4f3SwyWDrP30B2cOn0/qx2Cutu9F/YTLO+y+T5YXV3hrjOn+e6j32N7c5Ol8Zg9eza4eOk8sTVKur5M7ewQFmPEOU81GhJCIMS2JwjpACBdiyIlZW1jnT17Nrh85TJL4zFlWWWVqMBwOKaqBkwmNZcuPUfT1Jw6dYKbbz4GaL/5m1sXfv35zEr8h47dyXjvXWy3DYSncSlQOg/qiDHhfJpNSbl8nZN0zAF5jXZo6XzniJIyJkCSwyePJJPNdLncHVUgOpwohWtxCKn1BCqcW8INxrhqL8dPPcjK2sG+C/7KoK3desC2K2LJi81d92vCC8XSAW5/8KP8qK25+Px30OYsVZMYBU+KFUkaQlFbxTPVmYZSc1na8BuSQXyIElJjPPFBCQnaNtLUptpk8odQt2LZ71SJrVA3nkkrbNXCpMWkEWOeOcYOdxETgdh75BZ+67/8b/ngr/8zisEIcrXF0jc/k/XdQbuhmXFno6VVTt1yF03b8MzTPySmayjVbGBc89HGFWjKZScF32XB3aCvxv5rKz/bc3V7vmaij6gp30hGzScZsAUGykpxhpYOrQ2bhzy6lGKnh1uibpWiOsaBw/dy25kH2X/o8JzM2qI8/TNNU5YznN0P165dZTqZMJ1MWV1dYWNjH5cvXyKi+Ey+0PFDpzjLfmOKGbxD3iVybUKVuq65fOkKk+2apg2MhiPW1/dw001HWVpa5sc/fpJz585x4cIFhsMBKUXW1tb46K99hI2NdWaR4JVsEZh/puWm8sr6fu57+Nd57GtLvPDEl/A8SxWn+OBpnRCLiEtFZl/K88FioKkIeW05Ej4rdxlQq9OAI3m8lmg05gLvQGtIGogSTLkpmmJPCAk/HIJfQ8v9LG/cxu13vo2iGBkgO0W8y3zUL3szu9O0X1YC5PE/SRkuB8PlFW5997/g6rkn+N7f/zsmlx5Dm4uULutY15ormomU6lydzA+q2AxxMuR0GzwhQhtaA24FR2ohBCtJ19swmSSmE2hqMWrLYB/TxgJxjELHuBnJ1c5yzJ4Dx/nwx3+HD/z6P6MYjlHpp9vpKVVvAA35zo82df+fJayIONbWD3DHHW8hJc9zz10jRcEy3BYnYsLPqTDOWaIpfyi5hB3QlOktiTkozwi+tZsTJuXMKRJ6tLShoS2uu5z5Sh5bCoRgozUxWX8K8ag6nCzh/CH27b+X204/zNHjt+ILm5Oe7zMt7JXNDkO20XUAIBEYDocURcHm5hZN0+B9N1csLC0t575vTYxW+TAZzE5APJe78jwy0GeyIQRC2LIMzDk2N7d4/vlzrKxMKMuSlZUV6z+nxNLSmA984P2855F344tu2lDz61549ue2bp2J4+Rtd3HwwBH+7nMjnn/8/4PtJ6m0RZJQq+T+sKEybIcs8tqjGx3O60tyNgNkfysOE4fPI44hkGJLTBE/ENQVxFTitEJkQIwVg2o/d93/IW4+dTfOV/2Ry4SmEotDdWcZWS6C4q11oA5rDnTqahCHI/Ydv4d7q72cf/Ib/ODr/w+FPkMRLuO1xKmziidXSKnGCRnfgyGpFesV59GlroxtnNMwnUTqJlFPEtsTpWmEtoFpFOqgtG2iDUDyPaZApSC5Aj8YceDobfz27/4ev/KBX6UcjklkdYRuA8IRXa8wsKN2g7X95t+uY3VtH3fd9VZKD2efepSmBYiktIVivQZJNuBv6OoyZ7whz5lmBZ+uJ5xRm70Sk8acHZvYQCdkTiR/bbScKfNRx9gxP4XM1OMydd4yRXWIw0fu5b77H+H4iTvwGeTTJ1E9Ymyxeb+yzdht+uEYVW6//XZOnz7NY499P19/Y+kxdp7IYDAgxkhrN0eGDHRqWzb+JDIrT/ccuHljVbVKR107Ll68yJUrV1leXsY5x2g05MSJ47z73e/kkUd+hT17VuZGWqR/3Quf/vzW5UCgjFfXecf7f5O/0ciLP/xb3OQZCraJBLRt8YUBdjwFIXlDx2tCXWbcI6JY2TmZrACIkERIeRyqDQkNEYmJwnsLwMnkFFutwO9jY/9dnL73EY6fvBvxhYnN9HmevgT0Cbvd7w7D7tjIV5EXbVbfy3wKg0xjuefQEdb3HeT4mYd49Ct/xotnv8Lli49DuIqkFh+zHnwKeczQtI1BaWPMHNRKEzJtZWtzwm3j2d5ONI1j2ogF44D1lGM0wpAsv4svgYroBhTjPTzyoV/jk7/7e2wcOIIvvfFRkKk6M2jMQoLcELDezgfjPrPQ+XYutjkXrKxucMcdDzGoxvz4R19na9uKzlEvo2mblBpcyP0FCf1maaIPORj3vd8M0soo2YRRbSZN/eaQEmjIryCrN3VcyKaX2RJxmU1mjNMRw+FNHD32AHff8y5O3HKaajiwnlWf9ysqpk8izPPaLuyVbD7c3XnnaT7xiY/xt3/792xeu8Lzzz/HD554HBFhOq0JwWgxrbIyY02bjS3NytPAjOvcZfasZPddjAGQLOsHdV1z8/Gj/PZvfYK3vf1BlpZGr/AKX8kWh66faWLjhx6xqQgJDFeXueOt72M6UbbOfQvxz+Dry2hIpkVMxoJE6/mKc6izWYmUAZZJJKOjTT1IioKI0AbjMBYRKjek8FU+JjuUZdzgCIdOvo373/IB1vfdBNAf1uarIN28aedimePC33WmArHEedtcVewQ1Fc6u69Ucum6RQrHYHkvD/zyJ7l0/mG+8Jf/hovPP4qkS7jtGtIUTVMK3yLS9KjrFB0xlEwnLU0AVWcI6joxrRMhFjQttMERgyNGoU0tUR2tKlIMSJQkGVCOVrntzP2885EP8Y5feT/rG/tRJAsRpcxdbpMz5PdiNMqw046+gZnxK4MiRITl1T2cvuOt7Nk4xGPf+wovvPhda+xnHeIQAi451Df934hILi0ZUXzMnLQ2Q2HqTFG1Z6Xu5Y0TaLTTsGbycU1kMXMhpoqYSlSWUdZYWTrMrbe+jbvveZijx2+hqAbXvRvpF/Mig/qpNh/buhREYDwe8su//DBvect9TCYTfvjE4/xP//P/wtNPP4PIDMTVBWIRwXuPc1ZY6rRvgUwOIj1JSDI5FyOJ0khRDBiPR3jvaJspDz30Vh5++EHGS6MMBHw1PtRX8W92uSl44tzB1JDvN918C0tLe3ji0ZM8+f0v0lz+EQN/lXa6RZxuo8EmW1MgI20LA2/KgLZwFIMSTdDYjYGLLRJN39x5jy8q8COiK3ClQ8oRw+WbOXnHu7j93l9ibc9+ELExuG4EUaGj9+y51no5V3vtu9KEDIY1pHkPtpk7AKMmEEISnJZAQl1AvbJ2+BiP/Mbv0WxdJE2v8s3/9Jdcu/I8Lzz/fSbbz0K6jJcGiRFtFZKjmXjatrZplpaeZzokscCbyJoGjuhWCVKQyhJfjjl5y2nWN/bzS7/yPk7fdT/7Dx/LYhbg89m6bybOUe8K4DPWaKcBuDcoGF+fvVxvRqlXDcccvukUw9EyZ586xNknv8aVyz8kxhfRuEnSlqgtiCJ4EwXItJWiQgwzeS5Ry4CjZpx15jjtTsKa/23MwThFG5eI0RGTI+qYaniAgwfu4MydD3P6jrewsXc/vipmXSUlMz51gAbra+3SpftzmB1ehBkq3nthdXXM6uqY9fVlPvzhD/Pv/t2fsLl5jclkksUi5u6fvFEINr5iOqnkXKibGxScCKtrK4h31HXD+voagmNz8xr79u3lrrvvpBrkoX9JIPNVDXnJ54X9PCY2/mAKbeTSpihr+/Zy/zvfx4nTt/PVv/9T9OJzXD3/NGnzBVI7oZ0afWZoE3Vw1G3J9kS45iJb021SG9G25eCeFZYrZVREhqWj9CUDX1EOPFQV5coRVvbdwrFT93PPW95JUQ2sJKmK5IOczAVbzWjajgv/+kxp990DihJcxKvPiPfcyJdOvx26kVERn6kzTUugu3ara/uR1f1oUt596DSxnfK9R7/GlQvPUG++yA+/93WuXT7HlavPEZrtjPMoQR0ry+vW/6067IDDS2lTNslxYM9NHD91moPHTlAOl3ngobezZ2Mf4/ESZVXR6QmYKljCizeSJ3G5sWkZsVfNgkK7Bk39k2wuyxDFF459Bw6xtr6Hjb0HOPvkd3ju2Ue5evUsTX2ZFB3O1YjWeZg803yo9XpF5/iqU1aAiVaijtoBB8R4bJORRSQVoha0SYg6xLkN9u+9g1tuvZ+7734rBw8dYzhatrIZc7nTvONEFoH4Z9p1qfFLvsqjSaoURcGpU7dz33330bZTvv/Y97h48TLTaUOnX60p4cRbeSmPxKSQegQ9SfBFyZm7zvCRj3yEpIkv/acvcfbsWa5dvcqJm2/mw7/6Ye699y6KHrDl5m7Hn+bJhZd/ltkVcnOZpvQMdyrgy5J9h0/ywd/4r7h87lk+/6efZWm8zrVLZ/FcwV/bRieBSaNcmtQ8f37CC62jAQr1VNoyKmC0VuEqoagqysEyw6VVirV1BmuHOHzsDHff/07W9h3KGU9mnM4A2ll/+OX+nK3k3e3r+aVgVY68QPrCgcM7h+ZpFgvURT8n3m2W4qAs1imBt7zzI4gqbV1z7uknuXLpBT7zx/8nTzz+HaqBoyZx8NARfvtf/i7D0djWdq4/Sgb3JYWlpVX2HTzM+sZeTFDo5TUro1EWyKRNXVbfiZtctwvtrjljXgGZOt9E7mQUhbIacOzmO9i3/yg3nbudJ598lOeee4LL58/SNM8jegGnCScRdUqSABgVWwqJRJbfixBbK1e30dQ9kDxTlgRRjzIgyhhXLbH/4EmOH3uA07e9k5uP38JwNMD5WW/ylZatdcZ2+7J9FdYj3dzcD7T/6DRqnz93nq9+7ev84PEnaOvLrK+t4IBzL1xAxATHDUkPUtjO2lXUBlVpAgHOc/LkST760Y/y0EMPsrw85l3vegeXLl1ia2uTgwcPsrKykpm2utfyaj248PTPNBFbZzBDULyM/1fAL7F68BQf/O3fZ/Pi0zz2zS/xg69+ge3zT0ELMUCQgtaXxGD5alDHwAvD8ZDllSVG44qlPRuMlg9zy+m7ufWet7GyZz9FNaAoq9nzzjHjSVc+e9mhsFvlu7hXnE0QCimu+8lLv5xdM6tSvtI/7ey6wCNCNRpx9NbTHEm38T+evo+maTI3uR3IV1ZW+nak/clPd8bLfvtTDtUvC8I3yM9vsMyYfCGss9udX8HjxLM0XuPkyXs4fOgkV69c4Aff/Uce/fZfc/nSFNIWThJSRFyVGA4GDAdLEIRps0kTJqSsodmEYGwu3ThTdJCgdBusrh7n8LEzHL/lDKdO38nevccYDdYNJNIBOxZZ7+tm3Wx4d4EnkwnjpREnTx7n/AvC5uYVmmbKYFBQ4YnR2+hZJgVQwDtP4X0/JhVj4vz583zmM5/hG9/4Bh/60Ae45967WF5e/qkH4MUY0w0w5xgtrTEerbD30M0cP3kHX/jM/8GTj32bk7fexice+QSf/5vv8m//45/gXMchXLD3wDFO3XKCwWjEnsPHOHP/L3PoyAm88UnkvuArjSm9Ug61sBthqsbIt7q6OgfIpP/6lduavzgmO/kGReQa8NiOPeHLbR9w/gY9982quv8GPfeOmoi8CGxx4671ws87ZDd4Td9IP8Mu8vViTb/+ft7pYPwVVX1wx57wDfb8u8lu5LVe+HnnbOHn3WMLX7++tqCXWdjCFrawhS3sBtsiGC9sYQtb2MIWdoNtp4PxH+7w873Rnn832Y281gs/75wt/Lx7bOHr19F2tGe8sIUtbGELW9jCXm6LMvXCFrawhS1sYTfYdiwYi8iHReQxEXlcRP5gB57vxyLyLRH5uoh8Jf9sQ0T+QkR+kD/veb1fx26zhZ93jy18vTts4eedsR0JxiLigf8V+FXgTuBfiMidO/DUj6jq/XOQ+D8APqeqtwGfy98v7DWyhZ93jy18vTts4eeds53KjN8GPK6qP1TVBvg3wMd26Lnn7WPAH+Wv/wj4+A14Db/ItvDz7rGFr3eHLfy8Q7ZTwfgm4Ozc90/nn72epsCfi8hXReT3888Oqupz+evngYOv82vYbbbw8+6xha93hy38vEP2xuOmfu3sXar6jIgcAP5CRL43/0tVVRFZQMnf/Lbw8+6xha93h+1KP+9UZvwMcGzu+6P5Z6+bqeoz+fMLwGexcss5ETkMkD+/8Hq+hl1oCz/vHlv4enfYws87ZDsVjL8M3CYiJ0WkAv458O9frycTkSURWem+Bj4IfDs/56fyP/sU8Cev12vYpbbw8+6xha93hy38vEO2I2VqVQ0i8j8Af4YJXf7vqvro6/iUB4HPZgmuAvjXqvqnIvJl4I9F5NPAk8AnX8fXsOts4efdYwtf7w5b+HnnbMHAtbCFLWxhC1vYDbYFA9fCFrawhS1sYTfYFsF4YQtb2MIWtrAbbItgvLCFLWxhC1vYDbZFMF7Ywha2sIUt7AbbIhgvbGELW9jCFnaDbRGMF7awhS1sYQu7wbYIxgtb2MIWtrCF3WBbBOOFLWxhC1vYwm6w/f/4Dfc5p21RyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSJshqxly15d",
        "colab_type": "text"
      },
      "source": [
        "Since the data set of 77 kinds of fruits has more than 30,000 pictures, my computer can't bear the training of so many pictures, so I only select the first 20 categories in the dataset for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9E4tBXlKrZI",
        "colab_type": "text"
      },
      "source": [
        "Preprocess the dataset\n",
        "We need to augment the data, since we do not have many images per classes. Create an augmentation mechanism, data automatically does the following transformations during training:\n",
        "\n",
        "flip images horizontally\n",
        "rotates them\n",
        "performs zooming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1HQpHG0lXPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Since the data set is too large, first load a small part for training, n represents several classes\n",
        "def load_small_data(dir_path,m):\n",
        "    images_m=[] ##Create an empty list to store the picture collection\n",
        "    labels_m=[] ##Create an empty list to store the tag set\n",
        "    lab=os.listdir(dir_path)\n",
        "    n=0\n",
        "    for l in lab:\n",
        "        if(n>=m):\n",
        "            break\n",
        "        img=os.listdir(dir_path+l) ##img is the folder under the corresponding path\n",
        "        for i in img:\n",
        "            img_path=dir_path+l+'/'+i ##If yes, get the image path\n",
        "            labels_m.append(int(n)) ##Convert the upper folder of the picture to int type and store it in labels\n",
        "            images_m.append(skimage.io.imread(img_path)) ##Read the corresponding path image and store it in images_m\n",
        "        n+=1\n",
        "    return images_m,labels_m ## Class m labels and data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rAd-SoNy9Y3",
        "colab_type": "text"
      },
      "source": [
        "In the field of image processing, there are many ways, such as image denoising, translation, inversion, grayscale, cropping, etc., there will be some related processing functions below, but I did not use it in this experiment These above-mentioned processing methods simply convert the image data set into an array form, and chase it out of order, and perform keras unique encoding on the transition data set. I have used the grayscale image data set to train the model, and the result is that the accuracy of the test set prediction is reduced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA7uuT8FyBeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_20,labels_20=load_small_data(train_dir,20) ##Training set\n",
        "images_test_20,labels_test_20=load_small_data(validation_dir,20) ##Test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuSbWsJgzLAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Use list comprehension to complete batch cropping of images\n",
        "def cut_image(images,w,h):\n",
        "    new_images=[skimage.transform.resize(I,(w,h)) for I in images]\n",
        "    return new_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pBIpv2EzMvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Preprocessing data functions (arraying, out of order)\n",
        "def prepare_data(images,labels,n_classes):\n",
        "    ##images64=cut_image(images,64,64) ##Crop picture size is 64 * 64\n",
        "    train_x=np.array(images)\n",
        "    train_y=np.array(labels)\n",
        "    ##images_gray=color.rgb2gray(images_a) ##Grayscale\n",
        "    indx=np.arange(0,train_y.shape[0])\n",
        "    indx=shuffle(indx)\n",
        "    train_x=train_x[indx]\n",
        "    train_y=train_y[indx]\n",
        "    train_y=keras.utils.to_categorical(train_y,n_classes) ##one-hot coding\n",
        "    return train_x,train_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7AWE_ThzPfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Training set data preprocessing\n",
        "train_x,train_y=prepare_data(images_20,labels_20,20)\n",
        "##Test data set and label array and out of order\n",
        "test_x,test_y=prepare_data(images_test_20,labels_test_20,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3t2dGOtzUTj",
        "colab_type": "text"
      },
      "source": [
        "## Construction of Tensorflow convolutional neural network\n",
        "My convolutional neural network is a two-layer convolution pooling built with the classic model LeNet-5 model, three layers are fully connected, and the code has detailed comments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQUDa5G4XCEM",
        "colab_type": "text"
      },
      "source": [
        "Training the network\n",
        "Implement and train the following architecture. It has the following layers:\n",
        "\n",
        "A convolutional layer with 5x5 kernel and 32 filters\n",
        "A 2x2 MaxPooling layer\n",
        "Two convolutional layers with 3x3 kernels and 64 filters each\n",
        "A MaxPooling layer\n",
        "Another 3x3 convolutional layer with 128 filters, followed by a MaxPooling layer\n",
        "A fully connected layer of 512 units\n",
        "A final softmax layer\n",
        "All layers have ReLU activations. Train the network for 15 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EouooFlVzwKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZzTqcvvzWrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Configure the parameters of the neural network\n",
        "n_classes=20 ##Number of data categories\n",
        "batch_size=128 ##Training block size\n",
        "kernel_h=kernel_w=5 ##Convolution kernel size\n",
        "dropout=0.8 ##dropout probability\n",
        "depth_in=3 ##Picture channels\n",
        "depth_out1=64 ##Number of convolution kernels in the first layer of convolution\n",
        "depth_out2=128 ##Number of convolution kernels in the second layer of convolution\n",
        "image_size=train_x.shape[1] ##size of the picture\n",
        "n_sample=train_x.shape[0] ##Number of training samples\n",
        "t_sample=test_x.shape[0] ##Number of test samples\n",
        " \n",
        "##Feed image data types and shapes for neural networks, four-dimensional, the amount of training data in the first dimension, the size of the second and three-dimensional pictures,\n",
        "# and the number of image channels in the fourth dimension\n",
        "x=tf.placeholder(tf.float32,[None,100,100,3]) \n",
        "y=tf.placeholder(tf.float32,[None,n_classes]) ##The type and shape of label data feed to the neural network\n",
        "keep_prob=tf.placeholder(tf.float32) ##ddropout placeholder (solve overfitting)\n",
        "fla=int((image_size*image_size/16)*depth_out2) ##The size of the image used for the flattening process after\n",
        "# the two-layer convolution pooling * the number of convolution kernels in the second layer defines the weight variables of each convolution layer and the fully connected layer\n",
        "Weights={\"con1_w\":tf.Variable(tf.random_normal([kernel_h,kernel_w,depth_in,depth_out1])),\n",
        "         \"con2_w\":tf.Variable(tf.random_normal([kernel_h,kernel_w,depth_out1,depth_out2])),\n",
        "        \"fc_w1\":tf.Variable(tf.random_normal([int((image_size*image_size/16)*depth_out2),1024])),\n",
        "        \"fc_w2\":tf.Variable(tf.random_normal([1024,512])),\n",
        "        \"out\":tf.Variable(tf.random_normal([512,n_classes]))}\n",
        " \n",
        "##Define offset variables for each convolutional layer and fully connected layer\n",
        "bias={\"conv1_b\":tf.Variable(tf.random_normal([depth_out1])),\n",
        "      \"conv2_b\":tf.Variable(tf.random_normal([depth_out2])),\n",
        "      \"fc_b1\":tf.Variable(tf.random_normal([1024])),\n",
        "      \"fc_b2\":tf.Variable(tf.random_normal([512])),\n",
        "      \"out\":tf.Variable(tf.random_normal([n_classes]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-iWKBuzpT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define the generation function of the convolutional layer\n",
        "def conv2d(x,W,b,stride=1):\n",
        "    x=tf.nn.conv2d(x,W,strides=[1,stride,stride,1],padding=\"SAME\")\n",
        "    x=tf.nn.bias_add(x,b)\n",
        "    return tf.nn.relu(x)\n",
        " \n",
        "## Define the generation function of the pooling layer\n",
        "def maxpool2d(x,stride=2):\n",
        "    return tf.nn.max_pool(x,ksize=[1,stride,stride,1],strides=[1,stride,stride,1],padding=\"SAME\")\n",
        " \n",
        "## Define the generation function of convolutional neural network\n",
        "def conv_net(x,weights,biases,dropout):\n",
        "    \n",
        "    ## Convolutional layer 1\n",
        "    conv1 = conv2d(x,Weights['con1_w'],bias['conv1_b']) ##100*100*64\n",
        "    conv1 = maxpool2d(conv1,2) ##After pooling layer 1 shape：50*50*64\n",
        "     \n",
        "    ## Convolutional layer 2\n",
        "    conv2 = conv2d(conv1,Weights['con2_w'],bias['conv2_b']) ##50*50*128\n",
        "    conv2 = maxpool2d(conv2,2) ##After pooling layer 2 shape:25*25*128\n",
        "    ## Fully connected layer 1(\n",
        "    flatten = tf.reshape(conv2,[-1,fla]) ##Flatten\n",
        "    fc1 = tf.add(tf.matmul(flatten,Weights['fc_w1']),bias['fc_b1'])\n",
        "    fc1 = tf.nn.relu(fc1) ##After relu activation function\n",
        "    print(flatten.get_shape())\n",
        "    ## Fully connected layer 2\n",
        "    fc2 = tf.add(tf.matmul(fc1,Weights['fc_w2']),bias['fc_b2']) ##Calculation formula: output parameter = input parameter * weight + offset\n",
        "    fc2 = tf.nn.relu(fc2) ##After relu activation function\n",
        "    \n",
        "    ## Dropout layer prevents overfitting of predicted data\n",
        "    fc2 = tf.nn.dropout(fc2,dropout)\n",
        "    ## Output class prediction\n",
        "    prediction = tf.add(tf.matmul(fc2,Weights['out']),bias['out']) ##Output prediction parameters\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcflK-6L0Hm7",
        "colab_type": "code",
        "outputId": "caa7982b-4c7d-4753-fce2-83a3b7f0b9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "## Optimize prediction accuracy\n",
        "prediction=conv_net(x,Weights,bias,keep_prob) ##Generate convolutional neural network\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y)) ##Cross entropy loss function\n",
        "optimizer=tf.train.AdamOptimizer(0.0009).minimize(cross_entropy) ##Choose optimizer and learning rate\n",
        "##optimizer=tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
        "##optimizer=tf.train.AdagradOptimizer(0.001).minimize(cross_entropy) ##Choose optimizer and learning rate\n",
        " \n",
        "## Evaluation model\n",
        "correct_pred=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 80000)\n",
            "WARNING:tensorflow:From <ipython-input-155-c5957190636a>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D6M5vJn0NbS",
        "colab_type": "text"
      },
      "source": [
        "Here is a small function to divide the training data into n pieces of small data and feed it to the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJo7ZJcI0N-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Training block data generator\n",
        "def gen_small_data(inputs,batch_size):\n",
        "    i=0\n",
        "    while True:\n",
        "        small_data=inputs[i:(batch_size+i)]\n",
        "        i+=batch_size\n",
        "        yield small_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Bl3I7t0RUl",
        "colab_type": "text"
      },
      "source": [
        "Training data and view the accuracy of the model on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSKbzGBKK6oB",
        "colab_type": "text"
      },
      "source": [
        "Finally, calculate the performance of your model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2H0dimB0TBK",
        "colab_type": "code",
        "outputId": "c78ba734-bbd6-4605-d50c-0c4f954291ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Initial session and start training process\n",
        "with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()   \n",
        "    for  i  in range(5):\n",
        "        train_x,train_y=prepare_data(images_20,labels_20,20) ##Re-process data\n",
        "        train_x=gen_small_data(train_x,batch_size) ##Generate image block data\n",
        "        train_y=gen_small_data(train_y,batch_size) ##Generate label block data\n",
        "        for j in range(int(n_sample/batch_size)+1):\n",
        "            x_=next(train_x) \n",
        "            y_=next(train_y)\n",
        "            ##Prepare verification data\n",
        "            validate_feed={x:x_,y:y_,keep_prob:0.8}\n",
        "            if i % 1 == 0:\n",
        "                sess.run(optimizer, feed_dict=validate_feed)\n",
        "                loss,acc = sess.run([cross_entropy,accuracy],feed_dict={x:x_,y:y_,keep_prob:0.8})\n",
        "                print(\"Epoch:\", '%04d' % (i+1),\"cost=\", \"{:.9f}\".format(loss),\"Training accuracy\",\"{:.5f}\".format(acc))\n",
        "    print('Optimization Completed')\n",
        "    ##Prepare test data\n",
        "    test_x=test_x[0:400]\n",
        "    test_y=test_y[0:400]\n",
        "    test_feed={x:test_x,y:test_y,keep_prob: 0.8} \n",
        "    y1 = sess.run(prediction,feed_dict=test_feed)\n",
        "    test_classes = np.argmax(y1,1)\n",
        "    print('Testing Accuracy:',sess.run(accuracy,feed_dict=test_feed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 5273939968.000000000 Training accuracy 0.05469\n",
            "Epoch: 0001 cost= 5227146752.000000000 Training accuracy 0.09375\n",
            "Epoch: 0001 cost= 4303745024.000000000 Training accuracy 0.07812\n",
            "Epoch: 0001 cost= 3626212608.000000000 Training accuracy 0.10938\n",
            "Epoch: 0001 cost= 3233377280.000000000 Training accuracy 0.10938\n",
            "Epoch: 0001 cost= 3402319360.000000000 Training accuracy 0.10156\n",
            "Epoch: 0001 cost= 2790237184.000000000 Training accuracy 0.17969\n",
            "Epoch: 0001 cost= 2929535488.000000000 Training accuracy 0.10156\n",
            "Epoch: 0001 cost= 2273450496.000000000 Training accuracy 0.19531\n",
            "Epoch: 0001 cost= 2472119808.000000000 Training accuracy 0.14844\n",
            "Epoch: 0001 cost= 1696453376.000000000 Training accuracy 0.20312\n",
            "Epoch: 0001 cost= 1579098496.000000000 Training accuracy 0.17188\n",
            "Epoch: 0001 cost= 1449255680.000000000 Training accuracy 0.21094\n",
            "Epoch: 0001 cost= 1155407360.000000000 Training accuracy 0.29688\n",
            "Epoch: 0001 cost= 1499905536.000000000 Training accuracy 0.22656\n",
            "Epoch: 0001 cost= 1194873600.000000000 Training accuracy 0.35938\n",
            "Epoch: 0001 cost= 1225108608.000000000 Training accuracy 0.32031\n",
            "Epoch: 0001 cost= 1060923648.000000000 Training accuracy 0.32812\n",
            "Epoch: 0001 cost= 980649344.000000000 Training accuracy 0.35156\n",
            "Epoch: 0001 cost= 792245952.000000000 Training accuracy 0.39062\n",
            "Epoch: 0001 cost= 654004352.000000000 Training accuracy 0.47656\n",
            "Epoch: 0001 cost= 606043392.000000000 Training accuracy 0.49219\n",
            "Epoch: 0001 cost= 508805280.000000000 Training accuracy 0.46875\n",
            "Epoch: 0001 cost= 469810432.000000000 Training accuracy 0.51562\n",
            "Epoch: 0001 cost= 632371264.000000000 Training accuracy 0.48438\n",
            "Epoch: 0001 cost= 444855872.000000000 Training accuracy 0.50000\n",
            "Epoch: 0001 cost= 394481728.000000000 Training accuracy 0.50781\n",
            "Epoch: 0001 cost= 380394816.000000000 Training accuracy 0.50781\n",
            "Epoch: 0001 cost= 397119424.000000000 Training accuracy 0.53125\n",
            "Epoch: 0001 cost= 348213952.000000000 Training accuracy 0.59375\n",
            "Epoch: 0001 cost= 272800288.000000000 Training accuracy 0.59375\n",
            "Epoch: 0001 cost= 288812160.000000000 Training accuracy 0.66406\n",
            "Epoch: 0001 cost= 311047936.000000000 Training accuracy 0.64844\n",
            "Epoch: 0001 cost= 325563648.000000000 Training accuracy 0.61719\n",
            "Epoch: 0001 cost= 234320944.000000000 Training accuracy 0.72656\n",
            "Epoch: 0001 cost= 286300160.000000000 Training accuracy 0.57812\n",
            "Epoch: 0001 cost= 280395200.000000000 Training accuracy 0.64062\n",
            "Epoch: 0001 cost= 175049568.000000000 Training accuracy 0.67188\n",
            "Epoch: 0001 cost= 156662048.000000000 Training accuracy 0.72656\n",
            "Epoch: 0001 cost= 120798240.000000000 Training accuracy 0.74219\n",
            "Epoch: 0001 cost= 119423984.000000000 Training accuracy 0.77344\n",
            "Epoch: 0001 cost= 144995280.000000000 Training accuracy 0.74219\n",
            "Epoch: 0001 cost= 143743296.000000000 Training accuracy 0.76562\n",
            "Epoch: 0001 cost= 124281392.000000000 Training accuracy 0.74219\n",
            "Epoch: 0001 cost= 117901000.000000000 Training accuracy 0.76562\n",
            "Epoch: 0001 cost= 100704536.000000000 Training accuracy 0.78125\n",
            "Epoch: 0001 cost= 80937824.000000000 Training accuracy 0.82031\n",
            "Epoch: 0001 cost= 95177744.000000000 Training accuracy 0.80469\n",
            "Epoch: 0001 cost= 94877984.000000000 Training accuracy 0.82812\n",
            "Epoch: 0001 cost= 90498552.000000000 Training accuracy 0.84375\n",
            "Epoch: 0001 cost= 96368568.000000000 Training accuracy 0.82812\n",
            "Epoch: 0001 cost= 62871900.000000000 Training accuracy 0.82031\n",
            "Epoch: 0001 cost= 83273024.000000000 Training accuracy 0.78906\n",
            "Epoch: 0001 cost= 81397456.000000000 Training accuracy 0.77344\n",
            "Epoch: 0001 cost= 94600488.000000000 Training accuracy 0.80469\n",
            "Epoch: 0001 cost= 57742504.000000000 Training accuracy 0.85938\n",
            "Epoch: 0001 cost= 106128816.000000000 Training accuracy 0.79688\n",
            "Epoch: 0001 cost= 102349624.000000000 Training accuracy 0.78906\n",
            "Epoch: 0001 cost= 66608792.000000000 Training accuracy 0.82812\n",
            "Epoch: 0001 cost= 63554304.000000000 Training accuracy 0.85156\n",
            "Epoch: 0001 cost= 77999904.000000000 Training accuracy 0.82031\n",
            "Epoch: 0001 cost= 99094512.000000000 Training accuracy 0.77344\n",
            "Epoch: 0001 cost= 89538192.000000000 Training accuracy 0.82031\n",
            "Epoch: 0001 cost= 66692932.000000000 Training accuracy 0.82812\n",
            "Epoch: 0001 cost= 61912816.000000000 Training accuracy 0.83594\n",
            "Epoch: 0001 cost= 50092920.000000000 Training accuracy 0.87500\n",
            "Epoch: 0001 cost= 68971528.000000000 Training accuracy 0.89844\n",
            "Epoch: 0001 cost= 88660512.000000000 Training accuracy 0.85156\n",
            "Epoch: 0001 cost= 103721520.000000000 Training accuracy 0.83594\n",
            "Epoch: 0001 cost= 24449496.000000000 Training accuracy 0.89844\n",
            "Epoch: 0001 cost= 87978704.000000000 Training accuracy 0.79688\n",
            "Epoch: 0001 cost= 29644400.000000000 Training accuracy 0.89844\n",
            "Epoch: 0001 cost= 74737376.000000000 Training accuracy 0.85156\n",
            "Epoch: 0001 cost= 80402960.000000000 Training accuracy 0.83594\n",
            "Epoch: 0001 cost= 43270400.000000000 Training accuracy 0.88281\n",
            "Epoch: 0001 cost= 52083068.000000000 Training accuracy 0.85156\n",
            "Epoch: 0001 cost= 61808144.000000000 Training accuracy 0.85156\n",
            "Epoch: 0001 cost= 34878784.000000000 Training accuracy 0.91406\n",
            "Epoch: 0001 cost= 34258504.000000000 Training accuracy 0.87931\n",
            "Epoch: 0002 cost= 38494512.000000000 Training accuracy 0.88281\n",
            "Epoch: 0002 cost= 36140256.000000000 Training accuracy 0.89062\n",
            "Epoch: 0002 cost= 23440168.000000000 Training accuracy 0.91406\n",
            "Epoch: 0002 cost= 27932982.000000000 Training accuracy 0.88281\n",
            "Epoch: 0002 cost= 30810076.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 44658976.000000000 Training accuracy 0.87500\n",
            "Epoch: 0002 cost= 23701584.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 16393685.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 39323096.000000000 Training accuracy 0.89062\n",
            "Epoch: 0002 cost= 46453472.000000000 Training accuracy 0.86719\n",
            "Epoch: 0002 cost= 49088184.000000000 Training accuracy 0.86719\n",
            "Epoch: 0002 cost= 12229734.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 30263864.000000000 Training accuracy 0.87500\n",
            "Epoch: 0002 cost= 21996884.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 28723626.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 19453932.000000000 Training accuracy 0.90625\n",
            "Epoch: 0002 cost= 33816840.000000000 Training accuracy 0.91406\n",
            "Epoch: 0002 cost= 27124112.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 17649404.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 40379704.000000000 Training accuracy 0.88281\n",
            "Epoch: 0002 cost= 14603254.000000000 Training accuracy 0.96875\n",
            "Epoch: 0002 cost= 22572372.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 19583984.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 17506020.000000000 Training accuracy 0.90625\n",
            "Epoch: 0002 cost= 23608048.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 39386960.000000000 Training accuracy 0.91406\n",
            "Epoch: 0002 cost= 32802600.000000000 Training accuracy 0.87500\n",
            "Epoch: 0002 cost= 23046518.000000000 Training accuracy 0.89844\n",
            "Epoch: 0002 cost= 16314325.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 14159420.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 32546836.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 29297064.000000000 Training accuracy 0.90625\n",
            "Epoch: 0002 cost= 11053422.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 33440676.000000000 Training accuracy 0.90625\n",
            "Epoch: 0002 cost= 32023470.000000000 Training accuracy 0.91406\n",
            "Epoch: 0002 cost= 20672944.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 28156294.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 22814876.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 26919038.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 14161128.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 23382092.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 25107762.000000000 Training accuracy 0.89062\n",
            "Epoch: 0002 cost= 24108686.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 7529065.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 24095456.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 11524764.000000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 11749181.000000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 15761763.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 10941417.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 11707023.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0002 cost= 9614063.000000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 21664592.000000000 Training accuracy 0.91406\n",
            "Epoch: 0002 cost= 9557296.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 7762522.500000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 10844942.000000000 Training accuracy 0.93750\n",
            "Epoch: 0002 cost= 29227862.000000000 Training accuracy 0.92969\n",
            "Epoch: 0002 cost= 6366364.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 5589639.000000000 Training accuracy 0.97656\n",
            "Epoch: 0002 cost= 5165593.500000000 Training accuracy 0.97656\n",
            "Epoch: 0002 cost= 8373940.500000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 8938311.000000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 16947290.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 17965976.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 16293325.000000000 Training accuracy 0.94531\n",
            "Epoch: 0002 cost= 24668476.000000000 Training accuracy 0.89844\n",
            "Epoch: 0002 cost= 17885080.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 8725278.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 8677067.000000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 3859769.500000000 Training accuracy 0.98438\n",
            "Epoch: 0002 cost= 25916828.000000000 Training accuracy 0.92188\n",
            "Epoch: 0002 cost= 7375516.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 11066028.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 16764631.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 6666639.000000000 Training accuracy 0.96875\n",
            "Epoch: 0002 cost= 2900268.000000000 Training accuracy 0.97656\n",
            "Epoch: 0002 cost= 19707574.000000000 Training accuracy 0.95312\n",
            "Epoch: 0002 cost= 7662723.500000000 Training accuracy 0.96094\n",
            "Epoch: 0002 cost= 30247596.000000000 Training accuracy 0.87931\n",
            "Epoch: 0003 cost= 2697992.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 3364828.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 5993572.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 7366224.500000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 8329687.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 2283341.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 8951800.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 9895630.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 16750800.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 7465739.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 2297364.500000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 11620134.000000000 Training accuracy 0.92969\n",
            "Epoch: 0003 cost= 11030639.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 14777423.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 7116205.500000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 13718251.000000000 Training accuracy 0.94531\n",
            "Epoch: 0003 cost= 12311686.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 1798678.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 1596697.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 7687729.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 4926023.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 6379731.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 12819114.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 2327644.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 4652634.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 17043958.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 4535622.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 8324037.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 5778840.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 2253183.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 8580826.000000000 Training accuracy 0.93750\n",
            "Epoch: 0003 cost= 1726642.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 6013299.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 2775529.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 22040650.000000000 Training accuracy 0.94531\n",
            "Epoch: 0003 cost= 3373270.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 309488.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 3046041.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 12400106.000000000 Training accuracy 0.94531\n",
            "Epoch: 0003 cost= 5126901.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 7839725.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 14296836.000000000 Training accuracy 0.94531\n",
            "Epoch: 0003 cost= 18285910.000000000 Training accuracy 0.92188\n",
            "Epoch: 0003 cost= 4854302.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 6810858.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 4512044.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 15769279.000000000 Training accuracy 0.93750\n",
            "Epoch: 0003 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0003 cost= 16462266.000000000 Training accuracy 0.92969\n",
            "Epoch: 0003 cost= 10745439.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 9779397.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 12195324.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0003 cost= 7234184.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 4871764.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 5150468.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 8152400.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 2024264.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 1436938.500000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 2119811.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 2754723.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 3401950.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0003 cost= 3893006.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 3801080.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 4687223.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 5371761.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 11062322.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 584926.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 1308958.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 3639040.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 9123023.000000000 Training accuracy 0.96875\n",
            "Epoch: 0003 cost= 12603899.000000000 Training accuracy 0.97656\n",
            "Epoch: 0003 cost= 1278899.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 16531474.000000000 Training accuracy 0.95312\n",
            "Epoch: 0003 cost= 3253996.000000000 Training accuracy 0.99219\n",
            "Epoch: 0003 cost= 6067717.000000000 Training accuracy 0.96094\n",
            "Epoch: 0003 cost= 12674639.000000000 Training accuracy 0.98438\n",
            "Epoch: 0003 cost= 932577.125000000 Training accuracy 0.96552\n",
            "Epoch: 0004 cost= 1780530.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 4109379.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 6134084.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 365089.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 7637902.500000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 8487609.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 5949603.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 10151167.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 7564027.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 1793479.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 15862132.000000000 Training accuracy 0.92188\n",
            "Epoch: 0004 cost= 12348286.000000000 Training accuracy 0.95312\n",
            "Epoch: 0004 cost= 9167444.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 4283634.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 756803.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 3948438.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 2510034.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 6469674.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 9200989.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 8015578.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 3924173.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 1802917.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 3281459.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 13502382.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 13229978.000000000 Training accuracy 0.95312\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 6034481.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 1642928.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 15340061.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 4633216.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 2677294.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 6309319.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 15213691.000000000 Training accuracy 0.95312\n",
            "Epoch: 0004 cost= 10945732.000000000 Training accuracy 0.95312\n",
            "Epoch: 0004 cost= 2626640.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 12522472.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 11270885.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 4680984.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 8048887.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 4405458.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 1928512.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 418556.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 381598.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 1522957.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 14273031.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 1493510.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 8977028.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 880897.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 2818013.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 6463076.500000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 4773818.500000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 1670489.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 75376.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 985746.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 9769886.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 2798313.500000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 4252293.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 3265873.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 12112711.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 12627804.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 13584592.000000000 Training accuracy 0.96094\n",
            "Epoch: 0004 cost= 1245125.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 3973585.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 13013674.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 3536744.000000000 Training accuracy 0.97656\n",
            "Epoch: 0004 cost= 3134990.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 1362082.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 2993082.500000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 220616.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0004 cost= 6833735.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 369326.000000000 Training accuracy 0.99219\n",
            "Epoch: 0004 cost= 10981235.000000000 Training accuracy 0.96875\n",
            "Epoch: 0004 cost= 3190930.000000000 Training accuracy 0.98438\n",
            "Epoch: 0004 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 5536895.500000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 10739016.000000000 Training accuracy 0.96875\n",
            "Epoch: 0005 cost= 4325098.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 783488.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 6500739.000000000 Training accuracy 0.96094\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 7750282.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 1830332.250000000 Training accuracy 0.96875\n",
            "Epoch: 0005 cost= 4513687.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 6304686.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 6658126.000000000 Training accuracy 0.95312\n",
            "Epoch: 0005 cost= 9208596.000000000 Training accuracy 0.96094\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 912534.500000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 921927.500000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 3235437.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 1618471.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 2904353.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 3041435.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 2596606.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 1998921.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 3756628.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 3333340.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 4392430.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 3210273.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 927351.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 5379794.500000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 4953182.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 1185790.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 277275.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 3944850.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 2135311.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 7533697.500000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 1332528.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 150940.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 941778.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 1090986.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 6176594.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 1074852.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 5633713.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 99984.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 4753891.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 8322671.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 5939255.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 8031948.500000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 243528.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 743856.500000000 Training accuracy 0.96875\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 6439916.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 4315896.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 4174347.500000000 Training accuracy 0.96875\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Epoch: 0005 cost= 3832652.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 2513122.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 2431864.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 749242.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 5010953.500000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 8842652.000000000 Training accuracy 0.93750\n",
            "Epoch: 0005 cost= 2189497.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 6708290.500000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 6581133.500000000 Training accuracy 0.96875\n",
            "Epoch: 0005 cost= 5499778.000000000 Training accuracy 0.98438\n",
            "Epoch: 0005 cost= 1105791.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 2585926.000000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 10712484.000000000 Training accuracy 0.95312\n",
            "Epoch: 0005 cost= 4567846.500000000 Training accuracy 0.95312\n",
            "Epoch: 0005 cost= 4276718.000000000 Training accuracy 0.97656\n",
            "Epoch: 0005 cost= 3359648.250000000 Training accuracy 0.99219\n",
            "Epoch: 0005 cost= 0.000000000 Training accuracy 1.00000\n",
            "Optimization Completed\n",
            "Testing Accuracy: 0.9125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AZNH2chMznJ",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "My experiment only tested 20 kinds of fruits in the end, because my computer's configuration is not very good, and then it took about an hour to finish the optimization."
      ]
    }
  ]
}