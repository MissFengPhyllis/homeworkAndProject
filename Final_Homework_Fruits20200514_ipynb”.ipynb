{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final  Homework - Fruits20200514.ipynb”",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MissFengPhyllis/homeworkAndProject/blob/master/Final_Homework_Fruits20200514_ipynb%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xno3f36KY3Hb",
        "colab_type": "text"
      },
      "source": [
        "# Homework assignment - Fruits\n",
        "\n",
        "This notebook is the stub you have to fill out for the homework. Read the task description and implement the empty code cells. Each section represents a stage along implementing an image classifier from loading and inspecting the dataset to making something working. The section descriptions contain what to do in that step.\n",
        "\n",
        "Copy this notebook to your drive (File -> Save a copy in Drive), edit it and upload the final ipynb file to [canvas.elte.hu](https://canvas.elte.hu) or upload the link to the Colab notebook itself. If you have your own machine with Jupyter installed, you can work there as well.\n",
        "\n",
        "**Note** Make sure the notebook is using GPU accelerataion in Edit -> Notebook settings, otherwise training and evaluation can be very slow.\n",
        "\n",
        "## Task description\n",
        "Your task is to implement a deep learning classifier of fruit images. The dataset contains segmented images of 60 different fruits. You'll have to implement a convolutional network.\n",
        "\n",
        "## Rules and Comments\n",
        "- This is an ML class so to pass the homework you do have to implement a working classifier, just loading the data is not enough.\n",
        "- As always, copying others' code will make you fail the homework automatically (and thus the course)\n",
        "- Make sure your code can be run from an empty state (use Runtime -> Run all in the menu after restarting the notebook)\n",
        "- Feel free to add more code cells as needed. But don't put code into external Python files to ease the reviewing.\n",
        "- Please add your name and Neptun ID in the box below for easier identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2TVp9-YZlOj",
        "colab_type": "text"
      },
      "source": [
        "**Name: Feng Lijiao**  \n",
        "**Neptun ID: H2MI9D** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIPE7SRPQe7D",
        "colab_type": "code",
        "outputId": "ff38cd40-b67e-4819-d173-ab08c3e50c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Keras 2.3.1 has a bug in evalutation, downgrade it\n",
        "%tensorflow_version 1.x\n",
        "!pip install -U keras==2.2.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.18.4)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2dJzgxwZlYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some useful imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7vNIi7gZljF",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparations\n",
        "First download the data and extract it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-2-7vMqZs2w",
        "colab_type": "code",
        "outputId": "9d37b400-2197-479a-bef7-7a67984c649f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://vegesm.web.elte.hu/fruits_small.zip\n",
        "!unzip fruits_small.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-14 09:35:25--  http://vegesm.web.elte.hu/fruits_small.zip\n",
            "Resolving vegesm.web.elte.hu (vegesm.web.elte.hu)... 157.181.1.225\n",
            "Connecting to vegesm.web.elte.hu (vegesm.web.elte.hu)|157.181.1.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 186322919 (178M) [application/zip]\n",
            "Saving to: ‘fruits_small.zip’\n",
            "\n",
            "fruits_small.zip    100%[===================>] 177.69M   467KB/s    in 4m 18s  \n",
            "\n",
            "2020-05-14 09:40:21 (706 KB/s) - ‘fruits_small.zip’ saved [186322919/186322919]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu0jkvgLEdXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.placeholder error\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.reset_default_graph() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0PMTdx3ZxDM",
        "colab_type": "text"
      },
      "source": [
        "This will download and extract the dataset into `/content/fruits-small`. You can inspect the files in the sidebar on the left, under the *Files* tab. The dataset contains 100x100 pixel images of fruits, grouped by classes into folders. \n",
        "\n",
        "Notice that the dataset does not define a validation set, you have to split it yourself. Split the training set into a training and validation set. Make sure in the validation set the classes have a similar distribution to the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsD3bsCBBiUU",
        "colab_type": "text"
      },
      "source": [
        "Now that you have set up the dataset, it's time to look at some of \n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "the images. Create a function that randomly selects 4 images and prints them with the class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpy4iIhuxt65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show images \n",
        "import skimage\n",
        "from skimage import color,data,transform,io\n",
        "from sklearn.utils import shuffle\n",
        "import keras\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H19n5nYyVXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/fruits-small/\" \n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"test/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYZ5YmoXxKTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##Get the picture data under the corresponding path folder\n",
        "def load_data(dir_path):\n",
        "    no5_imgs=[] ##Create an empty list to store the fifth picture under each folder\n",
        "    labels_no5=[] ##Create an empty list to store the folder name corresponding to the fifth picture\n",
        "    lab=os.listdir(dir_path)\n",
        "    n=0\n",
        "    for l in lab:\n",
        "      img=os.listdir(dir_path+l) ##img is the folder under the corresponding path\n",
        "      n+=1\n",
        "      no5_img=format_path(img) ##Arrange the pictures in the correct order to facilitate the fifth picture\n",
        "      img5_path=dir_path+l+'/'+no5_img\n",
        "      labels_no5.append(l)\n",
        "      no5_imgs.append(skimage.io.imread(img5_path)) ##The fifth picture of each category is read out and stored in the data set no5_imgs\n",
        "    return no5_imgs,labels_no5 ##The storage order of the images in the returned images is different from the storage order in the actual folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15YlVPF7xXmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Function for sequentially reading files in a folder\n",
        "def format_path(img):  ## img is the result of os.listdir (label folder)   \n",
        "    yes_int=[] ##The new list is used to store the file name of the first item that can be converted into an integer\n",
        "    for s in range(len(img)): ##Iterate\n",
        "        img[s] = img[s].split('_') ##Separate file names with \"_\" as a separator\n",
        "        if(is_number(img[s][0])): ##Determine whether the first part of the file name can be converted to an integer\n",
        "            img[s][0]=int(img[s][0]) ##Convert the first part of the file name to an integer\n",
        "            yes_int.append(img[s]) ##Put the file name in the list without r\n",
        "    yes_int.sort() ##Sort the list of file names that can be converted to integer\n",
        "    for yi in range(len(yes_int)): ##variable\n",
        "        yes_int[yi][0]=str(yes_int[yi][0]) ##Convert the previous part to integer and then back to the string\n",
        "        yes_int[yi]=yes_int[yi][0]+'_'+yes_int[yi][1] ##Perform stitching\n",
        "    no5_img=yes_int[4]\n",
        "    return no5_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD-SnnB-xaxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Determine whether a piece of data can be converted to plastic\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        " \n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHOEOMf3xdi7",
        "colab_type": "code",
        "outputId": "c0a889c0-f007-4358-e05a-6cc5070341b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Final train data set and label\n",
        "no5_imgs,labels_no5 = load_data(train_dir)\n",
        "print(len(labels_no5),len(no5_imgs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgAbArIw4J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Call display function\n",
        "import random\n",
        "def display_no5_img_4(dict_no5):\n",
        "  fig = plt.figure(figsize=(15,15)) ##The displayed size is 15*15\n",
        "  for i in range(len(dict_no5)):\n",
        "    # print(i) //Subscript of dictionary list\n",
        "    # print(dict_list_no5[i][0])//Picture title\n",
        "    # print(dict_list_no5[i][1])//Picture matrix\n",
        "    plt.subplot(11,7,(i+1))\n",
        "    label = dict_no5[i][0]\n",
        "    img = dict_no5[i][1]\n",
        "    plt.title(\"{0}\".format(label))\n",
        "    plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgAwVutcw7Cg",
        "colab_type": "code",
        "outputId": "ec17eba3-370e-47a5-8e22-5628188b0f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "dict_no5 = zip(labels_no5,no5_imgs)\n",
        "dict_list_no5 = list(dict_no5) \n",
        "random_list = random.sample(dict_list_no5,4)\n",
        "display_no5_img_4(random_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EF8R3BVzXps",
        "colab_type": "text"
      },
      "source": [
        "in this code, you can run several times, each turn you can get a random 4 pictures "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12MJ6-jvHzSE",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the dataset\n",
        "\n",
        "Notice that the dataset does not define a validation set, you have to split it yourself. Split the training set into a training and validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PmnVHtkZzWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## notation definition\n",
        "import os\n",
        "IMAGE_HEIGHT = 100\n",
        "IMAGE_WIDTH = 100\n",
        "IMAGE_CHANNELS = 3\n",
        "NETWORK_DEPTH = 4\n",
        "data_dir = \"/content/fruits-small/\" \n",
        "train_dir = data_dir + \"train/\"\n",
        "validation_dir = data_dir + \"test/\"\n",
        "\n",
        "batch_size = 60\n",
        "input_size = IMAGE_HEIGHT * IMAGE_WIDTH * NETWORK_DEPTH\n",
        "num_classes = len(os.listdir(train_dir))\n",
        "# probability to keep the values after a training iteration\n",
        "dropout = 0.8\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "final_learning_rate = 0.00001\n",
        "learning_rate = initial_learning_rate\n",
        "\n",
        "# number of iterations to run the training\n",
        "# iterations = 75000\n",
        "iterations = 1500\n",
        "# number of iterations after we display the loss and accuracy\n",
        "acc_display_interval = 1000\n",
        "# default number of iterations after we save the model\n",
        "save_interval = 1000\n",
        "step_display_interval = 100\n",
        "# use the saved model and continue training\n",
        "useCkpt = False\n",
        "# placeholder for probability to keep the network parameters after an iteration\n",
        "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96pqblUgZ22J",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess the dataset\n",
        "\n",
        "We need to augment the data, since we do not have many images per classes. Create an augmentation mechanism, data automatically does the following transformations during training:\n",
        "- flip images horizontally\n",
        "- rotates them\n",
        "- performs zooming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1QBsrtFEuzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------- Write/Read TF record logic --------------------\n",
        "class ImageCoder(object):\n",
        "    \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Create a single Session to run all image coding calls.\n",
        "        self._sess = tf.Session()\n",
        "\n",
        "        # Initializes function that decodes RGB JPEG data.\n",
        "        self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
        "        self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
        "\n",
        "    def decode_jpeg(self, image_data):\n",
        "        image = self._sess.run(self._decode_jpeg,\n",
        "                               feed_dict={self._decode_jpeg_data: image_data})\n",
        "        assert len(image.shape) == 3    #  检查条件，不符合就终止程序\n",
        "        assert image.shape[2] == 3\n",
        "        return image\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaDrgOzME0v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_image_data(dir_name, tfrecords_name):\n",
        "    writer = tf.python_io.TFRecordWriter(tfrecords_name)\n",
        "    coder = ImageCoder()\n",
        "    image_count = 0\n",
        "    index = -1\n",
        "    classes_dict = {}\n",
        "\n",
        "    for folder_name in os.listdir(dir_name):\n",
        "        class_path = dir_name + '/' + folder_name + '/'\n",
        "        index += 1\n",
        "        classes_dict[index] = folder_name\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = class_path + image_name\n",
        "            image_count += 1\n",
        "            with tf.gfile.FastGFile(image_path, 'rb') as f:\n",
        "                image_data = f.read()\n",
        "                example = tf.train.Example(\n",
        "                    features = tf.train.Features(\n",
        "                        feature = {\n",
        "                            'label':tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n",
        "                            'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(image_data)]))\n",
        "                        }\n",
        "                    )\n",
        "                )\n",
        "                writer.write(example.SerializeToString())\n",
        "    writer.close()\n",
        "    print(classes_dict)\n",
        "    return image_count, classes_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjHAZuRCE6cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_single_example(serialized_example):\n",
        "    features = tf.parse_single_example(\n",
        "        serialized_example,\n",
        "        features={\n",
        "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "            'label': tf.FixedLenFeature([], tf.int64)\n",
        "        }\n",
        "    )\n",
        "    image = tf.image.decode_jpeg(features['image_raw'], channels=3)\n",
        "    image = tf.reshape(image, [100, 100, 3])\n",
        "    label = tf.cast(features['label'], tf.int32)\n",
        "    return image, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMv7XQWGFBB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(input_tensor,\n",
        "         name,\n",
        "         kernel_width,\n",
        "         kernel_height,\n",
        "         num_out_activation_maps,\n",
        "         stride_horizontal=1,\n",
        "         stride_vertical=1,\n",
        "         activation_fn=tf.nn.relu):\n",
        "    prev_layer_output = input_tensor.get_shape()[-1].value\n",
        "    with tf.variable_scope(name):\n",
        "        weights = tf.get_variable(\n",
        "            'weights', [\n",
        "                kernel_height, kernel_width, prev_layer_output,\n",
        "                num_out_activation_maps\n",
        "            ], tf.float32,\n",
        "            tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32))\n",
        "        biases = tf.get_variable(\"bias\", [num_out_activation_maps], tf.float32,\n",
        "                                 tf.constant_initializer(0.0))\n",
        "        conv_layer = tf.nn.conv2d(\n",
        "            input_tensor,\n",
        "            weights, (1, stride_horizontal, stride_vertical, 1),\n",
        "            padding='SAME')\n",
        "        activation = activation_fn(tf.nn.bias_add(conv_layer, biases))\n",
        "        return activation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xikG3sVaFDfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fully_connected(input_tensor,\n",
        "                    name,\n",
        "                    output_neurons,\n",
        "                    activation_fn=tf.nn.relu):\n",
        "    n_in = input_tensor.get_shape()[-1].value\n",
        "    with tf.variable_scope(name):\n",
        "        weights = tf.get_variable(\n",
        "            'weights', [n_in, output_neurons],\n",
        "            tf.float32,\n",
        "            initializer=tf.truncated_normal_initializer(\n",
        "                stddev=5e-2, dtype=tf.float32))\n",
        "        biases = tf.get_variable(\"bias\", [output_neurons], tf.float32,\n",
        "                                 tf.constant_initializer(0.0))\n",
        "        logits = tf.nn.bias_add(tf.matmul(input_tensor, weights), biases)\n",
        "        if activation_fn is None:\n",
        "            return logits\n",
        "        return activation_fn(logits)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPF6dSjFFF3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool(input_tensor, name, kernel_height, kernel_width,\n",
        "             stride_horizontal, stride_vertical):\n",
        "    return tf.nn.max_pool(\n",
        "        input_tensor,\n",
        "        ksize=[1, kernel_height, kernel_width, 1],\n",
        "        strides=[1, stride_horizontal, stride_vertical, 1],\n",
        "        padding='VALID',\n",
        "        name=name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjLr4S0-FIJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(logits, onehot_labels):\n",
        "    xentropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        logits=logits, labels=onehot_labels, name='xentropy')\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaIvDaGPFKBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_learning_rate(acc, learn_rate):\n",
        "    return learn_rate - acc * learn_rate * 0.9\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoH3ij3daCcf",
        "colab_type": "text"
      },
      "source": [
        "## Training the network\n",
        "\n",
        "Implement and train the following architecture. It has the following layers:\n",
        "\n",
        "- A convolutional layer with 5x5 kernel and 32 filters\n",
        "- A 2x2 MaxPooling layer\n",
        "- Two convolutional layers with 3x3 kernels and 64 filters each\n",
        "- A MaxPooling layer\n",
        "- Another 3x3 convolutional layer with 128 filters, followed by a MaxPooling layer\n",
        "- A fully connected layer of 512 units\n",
        "- A final softmax layer\n",
        "\n",
        "All layers have ReLU activations. Train the network for 15 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMfF7cJFFOc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def conv_net(input_layer, dropout):\n",
        "    # number of activation maps for each convolutional layer\n",
        "    number_of_act_maps_conv1 = 32\n",
        "    number_of_act_maps_conv2 = 64\n",
        "    number_of_act_maps_conv3 = 64\n",
        "    number_of_act_maps_conv4 = 128\n",
        "\n",
        "    # number of outputs for each fully connected layer\n",
        "    number_of_fcl_outputs1 = 512\n",
        "    number_of_fcl_outputs2 = 256\n",
        "\n",
        "    input_layer = tf.reshape(input_layer, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, NETWORK_DEPTH])\n",
        "\n",
        "    # A convolutional layer with 5x5 kernel and 32 filters\n",
        "    # A 2x2 MaxPooling layer\n",
        "    conv1 = conv(input_layer, 'conv1', kernel_width=5, kernel_height=5, num_out_activation_maps=number_of_act_maps_conv1)\n",
        "    conv1 = max_pool(conv1, 'max_pool1', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
        "\n",
        "    # Two convolutional layers with 3x3 kernels and 64 filters each\n",
        "    # A MaxPooling layer\n",
        "    conv2 = conv(conv1, 'conv2', kernel_width=3, kernel_height=3, num_out_activation_maps=number_of_act_maps_conv2)\n",
        "    conv2 = max_pool(conv2, 'max_pool2', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
        "\n",
        "   \n",
        "    conv3 = conv(conv2, 'conv3', kernel_width=3, kernel_height=3, num_out_activation_maps=number_of_act_maps_conv3)\n",
        "    conv3 = max_pool(conv3, 'max_pool3', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
        "\n",
        "    # Another 3x3 convolutional layer with 128 filters, followed by a MaxPooling layer\n",
        "    conv4 = conv(conv3, 'conv4', kernel_width=1, kernel_height=1, num_out_activation_maps=number_of_act_maps_conv4)\n",
        "    conv4 = max_pool(conv4, 'max_pool4', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
        "\n",
        "    flattened_shape = np.prod([s.value for s in conv4.get_shape()[1:]])\n",
        "    net = tf.reshape(conv4, [-1, flattened_shape], name=\"flatten\")\n",
        "\n",
        " \n",
        "\n",
        "    fcl1 = fully_connected(net, 'fcl1', number_of_fcl_outputs1)\n",
        "    fcl1 = tf.nn.dropout(fcl1, rate=1 - dropout)\n",
        "\n",
        "    fcl2 = fully_connected(fcl1, 'fcl2', number_of_fcl_outputs2)\n",
        "    fcl2 = tf.nn.dropout(fcl2, rate=1 - dropout)\n",
        "\n",
        "    # out = fully_connected(fcl2, 'out', num_classes, activation_fn=None)\n",
        "\n",
        "    #A fully connected layer of 512 units\n",
        "    out = fully_connected(net, 'out', 512, activation_fn=None)\n",
        "\n",
        "    return out\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKmW_hlFSJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# perform data augmentation on images\n",
        "# add random hue and saturation\n",
        "# randomly flip the image vertically and horizontally\n",
        "def augment_image(image):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.random_hue(image, 0.02)\n",
        "    image = tf.image.random_saturation(image, 0.9, 1.2)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return build_hsv_grayscale_image(image)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9A3Bp9nFTTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# converts the image from RGB to HSV and\n",
        "# adds a 4th channel to the HSV ones that contains the image in gray scale\n",
        "# for test just convert the image to HSV and add the gray scale channel\n",
        "def build_hsv_grayscale_image(image):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    gray_image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.image.rgb_to_hsv(image)\n",
        "    rez = tf.concat([image, gray_image], 2)\n",
        "    return rez\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_qWSF-RFVtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_datasets(train_file, test_file, batch_size):\n",
        "    train_dataset = tf.data.TFRecordDataset(train_file).repeat()\n",
        "    train_dataset = train_dataset.map(parse_single_example).map(\n",
        "        lambda image, label: (augment_image(image), label))\n",
        "    train_dataset = train_dataset.shuffle(\n",
        "        buffer_size=10000, reshuffle_each_iteration=True)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "    validation_dataset = tf.data.TFRecordDataset(train_file)\n",
        "    validation_dataset = validation_dataset.map(parse_single_example).map(\n",
        "        lambda image, label: (build_hsv_grayscale_image(image), label))\n",
        "    validation_dataset = validation_dataset.batch(batch_size)\n",
        "    \n",
        "    test_dataset = tf.data.TFRecordDataset(test_file)\n",
        "    test_dataset = test_dataset.map(parse_single_example).map(\n",
        "        lambda image, label: (build_hsv_grayscale_image(image), label))\n",
        "    test_dataset = test_dataset.batch(batch_size)\n",
        "    return train_dataset, validation_dataset, test_dataset\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikzZjeOrFYS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import time\n",
        "def train_model(session, train_operation, loss_operation, correct_prediction,\n",
        "                iterator_map):\n",
        "    global learning_rate\n",
        "    time1 = time.time()\n",
        "    train_iterator = iterator_map[\"train_iterator\"]\n",
        "    validation_iterator = iterator_map[\"validation_iterator\"]\n",
        "    validation_init_op = iterator_map[\"validation_init_op\"]\n",
        "    train_images_with_labels = train_iterator.get_next()\n",
        "    validation_images_with_labels = validation_iterator.get_next()\n",
        "    for i in range(1, iterations + 1):\n",
        "        batch_x, batch_y = session.run(train_images_with_labels)\n",
        "        batch_x = np.reshape(batch_x, [batch_size, input_size])\n",
        "        session.run(train_operation, feed_dict={X: batch_x, Y: batch_y})\n",
        "\n",
        "        if i % step_display_interval == 0:\n",
        "            time2 = time.time()\n",
        "            print(\"time: %.4f step: %d\" % (time2 - time1, i))\n",
        "            time1 = time.time()\n",
        "\n",
        "        if i % acc_display_interval == 0:\n",
        "            acc_value, loss = calculate_intermediate_accuracy_and_loss(\n",
        "                session, correct_prediction, loss_operation,\n",
        "                validation_images_with_labels, validation_init_op,\n",
        "                train_images_count)\n",
        "            learning_rate = update_learning_rate(\n",
        "                acc_value, learn_rate=learning_rate)\n",
        "            print(\"step: %d loss: %.4f accuracy: %.4f\" % (i, loss, acc_value))\n",
        "        if i % save_interval == 0:\n",
        "            # save the weights and the meta data for the graph\n",
        "            saver.save(session, './model.ckpt')\n",
        "            tf.train.write_graph(session.graph_def,'./', 'graph.pbtxt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NwIYDLxaGIe",
        "colab_type": "text"
      },
      "source": [
        "Now, that the model has finished training, plot the accuracy and loss over time, both for training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia8iHrNMGA4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_intermediate_accuracy_and_loss(session, correct_prediction, loss_operation, test_images_with_labels, test_init_op, total_image_count):\n",
        "    sess.run(test_init_op)\n",
        "    loss = 0\n",
        "    predicted = 0\n",
        "    count = 0\n",
        "    total = 0\n",
        "    while total < total_image_count:\n",
        "        test_batch_x, test_batch_y = session.run(test_images_with_labels)\n",
        "        test_batch_x = np.reshape(test_batch_x, [-1, input_size])\n",
        "        l, p = session.run([loss_operation, correct_prediction], feed_dict={X: test_batch_x, Y: test_batch_y})\n",
        "        loss += l\n",
        "        predicted += np.sum(p)\n",
        "        count += 1\n",
        "        total += len(p)\n",
        "    return predicted / total_image_count, loss / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djzh2uUDGGpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(sess, pred, iterator, total_images, file_name):\n",
        "    images_left_to_process = total_images\n",
        "    total_number_of_images = total_images\n",
        "    images_with_labels = iterator.get_next()\n",
        "    correct = 0\n",
        "    while images_left_to_process > 0:\n",
        "        batch_x, batch_y = sess.run(images_with_labels)\n",
        "        batch_x = np.reshape(batch_x, [-1, input_size])\n",
        "        # the results of the classification is an array of 1 and 0, 1 is a correct classification\n",
        "        results = sess.run(pred, feed_dict={X: batch_x, Y: batch_y})\n",
        "        images_left_to_process = images_left_to_process - len(results)\n",
        "        correct = correct + np.sum(results)\n",
        "        print(\"Predicted %d out of %d; partial accuracy %.4f\" % (correct, total_number_of_images - images_left_to_process,\n",
        "                                                                 correct / (total_number_of_images - images_left_to_process)))\n",
        "    print(\"Final accuracy on %s data: %.8f\" % (file_name, correct / total_number_of_images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8KA280ComY",
        "colab_type": "text"
      },
      "source": [
        "Finally, calculate the performance of your model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8NQp8BtGTCi",
        "colab_type": "code",
        "outputId": "94262b6d-622f-4b6e-f489-b20966e33114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "tf.reset_default_graph() \n",
        "# ------------------------------------------------------------\n",
        "train_images_count, fruit_labels = write_image_data(train_dir, \"train.tfrecord\")\n",
        "test_images_count, _ = write_image_data(validation_dir, \"test.tfrecord\")\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # placeholder for input layer\n",
        "    X = tf.placeholder(tf.float32, [None, input_size], name=\"X\")\n",
        "    # placeholder for actual labels\n",
        "    Y = tf.placeholder(tf.int64, [None], name=\"Y\")\n",
        "    \n",
        "    # build the network\n",
        "    logits = conv_net(input_layer=X, dropout=dropout)\n",
        "    # apply softmax on the final layer\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "    \n",
        "    # calculate the loss using the predicted labels vs the expected labels\n",
        "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
        "    # use adaptive moment estimation optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(loss=loss)\n",
        "    \n",
        "    # calculate the accuracy for this training step\n",
        "    correct_prediction = tf.equal(tf.argmax(prediction, 1), Y)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    \n",
        "    # input tfrecord file\n",
        "    train_file = \"train.tfrecord\"\n",
        "    test_file = \"test.tfrecord\"\n",
        "    train_dataset, validation_dataset, test_dataset = build_datasets(train_file, test_file, batch_size)\n",
        "    \n",
        "    train_iterator = train_dataset.make_one_shot_iterator()\n",
        "    validation_iterator = tf.data.Iterator.from_structure(validation_dataset.output_types, validation_dataset.output_shapes)\n",
        "    validation_init_op = validation_iterator.make_initializer(validation_dataset)\n",
        "    iterator_map = {\"train_iterator\": train_iterator,\n",
        "                    \"validation_iterator\": validation_iterator,\n",
        "                    \"validation_init_op\": validation_init_op}\n",
        "    test_iterator = test_dataset.make_one_shot_iterator()\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "    sess.run(init)\n",
        "    # restore the previously saved value if we wish to continue the training\n",
        "    if useCkpt:\n",
        "        ckpt = tf.train.get_checkpoint_state(\".\")\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "    train_model(sess, train_op, loss, correct_prediction, iterator_map)\n",
        "    \n",
        "    test_model(sess, correct_prediction, test_iterator, test_images_count, test_file)\n",
        "    \n",
        "    sess.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'Tomato 3', 1: 'Cherry Wax Red', 2: 'Onion Red Peeled', 3: 'Kohlrabi', 4: 'Tomato Cherry Red', 5: 'Orange', 6: 'Pear', 7: 'Pear Forelle', 8: 'Tomato 1', 9: 'Granadilla', 10: 'Pepper Green', 11: 'Peach 2', 12: 'Physalis with Husk', 13: 'Carambula', 14: 'Cherry Rainier', 15: 'Banana', 16: 'Pear Williams', 17: 'Kaki', 18: 'Maracuja', 19: 'Redcurrant', 20: 'Pepper Yellow', 21: 'Grape White 4', 22: 'Rambutan', 23: 'Grape Pink', 24: 'Nut Pecan', 25: 'Tamarillo', 26: 'Hazelnut', 27: 'Grapefruit White', 28: 'Pineapple Mini', 29: 'Passion Fruit', 30: 'Lemon', 31: 'Apple Red Delicious', 32: 'Apple Golden 1', 33: 'Pomelo Sweetie', 34: 'Apple Red 2', 35: 'Plum', 36: 'Limes', 37: 'Blueberry', 38: 'Eggplant', 39: 'Mandarine', 40: 'Avocado', 41: 'Potato White', 42: 'Nectarine Flat', 43: 'Potato Red Washed', 44: 'Tomato Yellow', 45: 'Cherry 1', 46: 'Mulberry', 47: 'Plum 3', 48: 'Apple Pink Lady', 49: 'Apple Golden 3', 50: 'Cantaloupe 1', 51: 'Pear Monster', 52: 'Cocos', 53: 'Strawberry', 54: 'Banana Red', 55: 'Apple Red Yellow 2', 56: 'Apple Braeburn', 57: 'Chestnut', 58: 'Grape White 2', 59: 'Mango Red'}\n",
            "{0: 'Tomato 3', 1: 'Cherry Wax Red', 2: 'Onion Red Peeled', 3: 'Kohlrabi', 4: 'Tomato Cherry Red', 5: 'Orange', 6: 'Pear', 7: 'Pear Forelle', 8: 'Tomato 1', 9: 'Granadilla', 10: 'Pepper Green', 11: 'Peach 2', 12: 'Physalis with Husk', 13: 'Carambula', 14: 'Cherry Rainier', 15: 'Banana', 16: 'Pear Williams', 17: 'Kaki', 18: 'Maracuja', 19: 'Redcurrant', 20: 'Pepper Yellow', 21: 'Grape White 4', 22: 'Rambutan', 23: 'Grape Pink', 24: 'Nut Pecan', 25: 'Tamarillo', 26: 'Hazelnut', 27: 'Grapefruit White', 28: 'Pineapple Mini', 29: 'Passion Fruit', 30: 'Lemon', 31: 'Apple Red Delicious', 32: 'Apple Golden 1', 33: 'Pomelo Sweetie', 34: 'Apple Red 2', 35: 'Plum', 36: 'Limes', 37: 'Blueberry', 38: 'Eggplant', 39: 'Mandarine', 40: 'Avocado', 41: 'Potato White', 42: 'Nectarine Flat', 43: 'Potato Red Washed', 44: 'Tomato Yellow', 45: 'Cherry 1', 46: 'Mulberry', 47: 'Plum 3', 48: 'Apple Pink Lady', 49: 'Apple Golden 3', 50: 'Cantaloupe 1', 51: 'Pear Monster', 52: 'Cocos', 53: 'Strawberry', 54: 'Banana Red', 55: 'Apple Red Yellow 2', 56: 'Apple Braeburn', 57: 'Chestnut', 58: 'Grape White 2', 59: 'Mango Red'}\n",
            "WARNING:tensorflow:Entity <function build_datasets.<locals>.<lambda> at 0x7fcba13b2730> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function build_datasets.<locals>.<lambda> at 0x7fcba13b2730> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <function build_datasets.<locals>.<lambda> at 0x7fcbf07cd158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function build_datasets.<locals>.<lambda> at 0x7fcbf07cd158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <function build_datasets.<locals>.<lambda> at 0x7fcbf078e048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function build_datasets.<locals>.<lambda> at 0x7fcbf078e048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "time: 29.3371 step: 100\n",
            "time: 14.6256 step: 200\n",
            "time: 14.4681 step: 300\n",
            "time: 14.4200 step: 400\n",
            "time: 14.3168 step: 500\n",
            "time: 14.5381 step: 600\n",
            "time: 14.2921 step: 700\n",
            "time: 14.4708 step: 800\n",
            "time: 14.2735 step: 900\n",
            "time: 14.3544 step: 1000\n",
            "step: 1000 loss: 0.0278 accuracy: 0.9917\n",
            "time: 58.1516 step: 1100\n",
            "time: 14.3948 step: 1200\n",
            "time: 14.7485 step: 1300\n",
            "time: 14.1949 step: 1400\n",
            "time: 14.2702 step: 1500\n",
            "Predicted 60 out of 60; partial accuracy 1.0000\n",
            "Predicted 120 out of 120; partial accuracy 1.0000\n",
            "Predicted 180 out of 180; partial accuracy 1.0000\n",
            "Predicted 240 out of 240; partial accuracy 1.0000\n",
            "Predicted 300 out of 300; partial accuracy 1.0000\n",
            "Predicted 360 out of 360; partial accuracy 1.0000\n",
            "Predicted 420 out of 420; partial accuracy 1.0000\n",
            "Predicted 480 out of 480; partial accuracy 1.0000\n",
            "Predicted 540 out of 540; partial accuracy 1.0000\n",
            "Predicted 600 out of 600; partial accuracy 1.0000\n",
            "Predicted 660 out of 660; partial accuracy 1.0000\n",
            "Predicted 720 out of 720; partial accuracy 1.0000\n",
            "Predicted 780 out of 780; partial accuracy 1.0000\n",
            "Predicted 840 out of 840; partial accuracy 1.0000\n",
            "Predicted 900 out of 900; partial accuracy 1.0000\n",
            "Predicted 960 out of 960; partial accuracy 1.0000\n",
            "Predicted 1020 out of 1020; partial accuracy 1.0000\n",
            "Predicted 1080 out of 1080; partial accuracy 1.0000\n",
            "Predicted 1140 out of 1140; partial accuracy 1.0000\n",
            "Predicted 1200 out of 1200; partial accuracy 1.0000\n",
            "Predicted 1260 out of 1260; partial accuracy 1.0000\n",
            "Predicted 1320 out of 1320; partial accuracy 1.0000\n",
            "Predicted 1380 out of 1380; partial accuracy 1.0000\n",
            "Predicted 1440 out of 1440; partial accuracy 1.0000\n",
            "Predicted 1500 out of 1500; partial accuracy 1.0000\n",
            "Predicted 1560 out of 1560; partial accuracy 1.0000\n",
            "Predicted 1620 out of 1620; partial accuracy 1.0000\n",
            "Predicted 1680 out of 1680; partial accuracy 1.0000\n",
            "Predicted 1739 out of 1740; partial accuracy 0.9994\n",
            "Predicted 1797 out of 1800; partial accuracy 0.9983\n",
            "Predicted 1854 out of 1860; partial accuracy 0.9968\n",
            "Predicted 1914 out of 1920; partial accuracy 0.9969\n",
            "Predicted 1974 out of 1980; partial accuracy 0.9970\n",
            "Predicted 2034 out of 2040; partial accuracy 0.9971\n",
            "Predicted 2094 out of 2100; partial accuracy 0.9971\n",
            "Predicted 2154 out of 2160; partial accuracy 0.9972\n",
            "Predicted 2214 out of 2220; partial accuracy 0.9973\n",
            "Predicted 2274 out of 2280; partial accuracy 0.9974\n",
            "Predicted 2334 out of 2340; partial accuracy 0.9974\n",
            "Predicted 2393 out of 2400; partial accuracy 0.9971\n",
            "Predicted 2438 out of 2460; partial accuracy 0.9911\n",
            "Predicted 2468 out of 2520; partial accuracy 0.9794\n",
            "Predicted 2509 out of 2580; partial accuracy 0.9725\n",
            "Predicted 2569 out of 2640; partial accuracy 0.9731\n",
            "Predicted 2629 out of 2700; partial accuracy 0.9737\n",
            "Predicted 2689 out of 2760; partial accuracy 0.9743\n",
            "Predicted 2749 out of 2820; partial accuracy 0.9748\n",
            "Predicted 2791 out of 2880; partial accuracy 0.9691\n",
            "Predicted 2836 out of 2940; partial accuracy 0.9646\n",
            "Predicted 2882 out of 3000; partial accuracy 0.9607\n",
            "Predicted 2930 out of 3060; partial accuracy 0.9575\n",
            "Predicted 2974 out of 3120; partial accuracy 0.9532\n",
            "Predicted 3022 out of 3180; partial accuracy 0.9503\n",
            "Predicted 3082 out of 3240; partial accuracy 0.9512\n",
            "Predicted 3142 out of 3300; partial accuracy 0.9521\n",
            "Predicted 3201 out of 3360; partial accuracy 0.9527\n",
            "Predicted 3257 out of 3420; partial accuracy 0.9523\n",
            "Predicted 3316 out of 3480; partial accuracy 0.9529\n",
            "Predicted 3372 out of 3540; partial accuracy 0.9525\n",
            "Predicted 3428 out of 3600; partial accuracy 0.9522\n",
            "Predicted 3484 out of 3660; partial accuracy 0.9519\n",
            "Predicted 3544 out of 3720; partial accuracy 0.9527\n",
            "Predicted 3604 out of 3780; partial accuracy 0.9534\n",
            "Predicted 3664 out of 3840; partial accuracy 0.9542\n",
            "Predicted 3724 out of 3900; partial accuracy 0.9549\n",
            "Predicted 3784 out of 3960; partial accuracy 0.9556\n",
            "Predicted 3844 out of 4020; partial accuracy 0.9562\n",
            "Predicted 3904 out of 4080; partial accuracy 0.9569\n",
            "Predicted 3964 out of 4140; partial accuracy 0.9575\n",
            "Predicted 4024 out of 4200; partial accuracy 0.9581\n",
            "Predicted 4080 out of 4260; partial accuracy 0.9577\n",
            "Predicted 4138 out of 4320; partial accuracy 0.9579\n",
            "Predicted 4197 out of 4380; partial accuracy 0.9582\n",
            "Predicted 4257 out of 4440; partial accuracy 0.9588\n",
            "Predicted 4317 out of 4500; partial accuracy 0.9593\n",
            "Predicted 4377 out of 4560; partial accuracy 0.9599\n",
            "Predicted 4437 out of 4620; partial accuracy 0.9604\n",
            "Predicted 4497 out of 4680; partial accuracy 0.9609\n",
            "Predicted 4557 out of 4740; partial accuracy 0.9614\n",
            "Predicted 4617 out of 4800; partial accuracy 0.9619\n",
            "Predicted 4677 out of 4860; partial accuracy 0.9623\n",
            "Predicted 4737 out of 4920; partial accuracy 0.9628\n",
            "Predicted 4797 out of 4980; partial accuracy 0.9633\n",
            "Predicted 4854 out of 5040; partial accuracy 0.9631\n",
            "Predicted 4910 out of 5100; partial accuracy 0.9627\n",
            "Predicted 4959 out of 5160; partial accuracy 0.9610\n",
            "Predicted 5016 out of 5220; partial accuracy 0.9609\n",
            "Predicted 5076 out of 5280; partial accuracy 0.9614\n",
            "Predicted 5136 out of 5340; partial accuracy 0.9618\n",
            "Predicted 5175 out of 5400; partial accuracy 0.9583\n",
            "Predicted 5205 out of 5460; partial accuracy 0.9533\n",
            "Predicted 5240 out of 5520; partial accuracy 0.9493\n",
            "Predicted 5300 out of 5580; partial accuracy 0.9498\n",
            "Predicted 5360 out of 5640; partial accuracy 0.9504\n",
            "Predicted 5419 out of 5700; partial accuracy 0.9507\n",
            "Predicted 5479 out of 5760; partial accuracy 0.9512\n",
            "Predicted 5539 out of 5820; partial accuracy 0.9517\n",
            "Predicted 5599 out of 5880; partial accuracy 0.9522\n",
            "Predicted 5659 out of 5940; partial accuracy 0.9527\n",
            "Predicted 5719 out of 6000; partial accuracy 0.9532\n",
            "Predicted 5779 out of 6060; partial accuracy 0.9536\n",
            "Predicted 5839 out of 6120; partial accuracy 0.9541\n",
            "Predicted 5899 out of 6180; partial accuracy 0.9545\n",
            "Predicted 5959 out of 6240; partial accuracy 0.9550\n",
            "Predicted 6019 out of 6300; partial accuracy 0.9554\n",
            "Predicted 6079 out of 6360; partial accuracy 0.9558\n",
            "Predicted 6139 out of 6420; partial accuracy 0.9562\n",
            "Predicted 6199 out of 6480; partial accuracy 0.9566\n",
            "Predicted 6259 out of 6540; partial accuracy 0.9570\n",
            "Predicted 6319 out of 6600; partial accuracy 0.9574\n",
            "Predicted 6374 out of 6660; partial accuracy 0.9571\n",
            "Predicted 6413 out of 6720; partial accuracy 0.9543\n",
            "Predicted 6455 out of 6780; partial accuracy 0.9521\n",
            "Predicted 6509 out of 6840; partial accuracy 0.9516\n",
            "Predicted 6569 out of 6900; partial accuracy 0.9520\n",
            "Predicted 6629 out of 6960; partial accuracy 0.9524\n",
            "Predicted 6689 out of 7020; partial accuracy 0.9528\n",
            "Predicted 6749 out of 7080; partial accuracy 0.9532\n",
            "Predicted 6809 out of 7140; partial accuracy 0.9536\n",
            "Predicted 6869 out of 7200; partial accuracy 0.9540\n",
            "Predicted 6927 out of 7260; partial accuracy 0.9541\n",
            "Predicted 6976 out of 7320; partial accuracy 0.9530\n",
            "Predicted 7034 out of 7380; partial accuracy 0.9531\n",
            "Predicted 7093 out of 7440; partial accuracy 0.9534\n",
            "Predicted 7153 out of 7500; partial accuracy 0.9537\n",
            "Predicted 7213 out of 7560; partial accuracy 0.9541\n",
            "Predicted 7273 out of 7620; partial accuracy 0.9545\n",
            "Predicted 7333 out of 7680; partial accuracy 0.9548\n",
            "Predicted 7393 out of 7740; partial accuracy 0.9552\n",
            "Predicted 7453 out of 7800; partial accuracy 0.9555\n",
            "Predicted 7513 out of 7860; partial accuracy 0.9559\n",
            "Predicted 7573 out of 7920; partial accuracy 0.9562\n",
            "Predicted 7633 out of 7980; partial accuracy 0.9565\n",
            "Predicted 7693 out of 8040; partial accuracy 0.9568\n",
            "Predicted 7753 out of 8100; partial accuracy 0.9572\n",
            "Predicted 7813 out of 8160; partial accuracy 0.9575\n",
            "Predicted 7873 out of 8220; partial accuracy 0.9578\n",
            "Predicted 7933 out of 8280; partial accuracy 0.9581\n",
            "Predicted 7993 out of 8340; partial accuracy 0.9584\n",
            "Predicted 8053 out of 8400; partial accuracy 0.9587\n",
            "Predicted 8113 out of 8460; partial accuracy 0.9590\n",
            "Predicted 8167 out of 8520; partial accuracy 0.9586\n",
            "Predicted 8215 out of 8580; partial accuracy 0.9575\n",
            "Predicted 8263 out of 8640; partial accuracy 0.9564\n",
            "Predicted 8317 out of 8700; partial accuracy 0.9560\n",
            "Predicted 8377 out of 8760; partial accuracy 0.9563\n",
            "Predicted 8437 out of 8820; partial accuracy 0.9566\n",
            "Predicted 8497 out of 8880; partial accuracy 0.9569\n",
            "Predicted 8557 out of 8940; partial accuracy 0.9572\n",
            "Predicted 8616 out of 9000; partial accuracy 0.9573\n",
            "Predicted 8671 out of 9060; partial accuracy 0.9571\n",
            "Predicted 8730 out of 9120; partial accuracy 0.9572\n",
            "Predicted 8785 out of 9180; partial accuracy 0.9570\n",
            "Predicted 8845 out of 9240; partial accuracy 0.9573\n",
            "Predicted 8905 out of 9300; partial accuracy 0.9575\n",
            "Predicted 8958 out of 9360; partial accuracy 0.9571\n",
            "Predicted 9003 out of 9420; partial accuracy 0.9557\n",
            "Predicted 9054 out of 9480; partial accuracy 0.9551\n",
            "Predicted 9112 out of 9540; partial accuracy 0.9551\n",
            "Predicted 9172 out of 9600; partial accuracy 0.9554\n",
            "Predicted 9232 out of 9660; partial accuracy 0.9557\n",
            "Predicted 9285 out of 9720; partial accuracy 0.9552\n",
            "Predicted 9323 out of 9780; partial accuracy 0.9533\n",
            "Predicted 9360 out of 9840; partial accuracy 0.9512\n",
            "Predicted 9410 out of 9900; partial accuracy 0.9505\n",
            "Predicted 9467 out of 9960; partial accuracy 0.9505\n",
            "Predicted 9524 out of 10020; partial accuracy 0.9505\n",
            "Predicted 9584 out of 10080; partial accuracy 0.9508\n",
            "Predicted 9644 out of 10140; partial accuracy 0.9511\n",
            "Predicted 9704 out of 10200; partial accuracy 0.9514\n",
            "Predicted 9762 out of 10260; partial accuracy 0.9515\n",
            "Predicted 9818 out of 10320; partial accuracy 0.9514\n",
            "Predicted 9830 out of 10332; partial accuracy 0.9514\n",
            "Final accuracy on test.tfrecord data: 0.95141309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOb7krvZaGZ2",
        "colab_type": "text"
      },
      "source": [
        "How did the loss and accuracy curves change over time? What does it mean regarding the training process (i.e. overfit, underfit, etc.)? Is that a problem and how would you solve it?\n",
        "\n",
        "**Write your answers below**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFxnT7DItmu-",
        "colab_type": "text"
      },
      "source": [
        "#### **summary**\n",
        "Loss decreases with increasing time, and accuracy increases with increasing time.\n",
        "\n",
        "From the model test results above, when the number of iterations is 100, the running time is 29.3317 seconds, but when iterating to 1500 times, the running time is 14.2702, which is enough to prove that the loss decreases with time; then It is accuracy. This time at the beginning, the test set has an accuracy of 1, but as the number of test sets increases, the accuracy is gradually decreasing, but the overall accuracy is still guaranteed to be around 95%.\n",
        "\n",
        "So at the beginning, the test set had a serious overfitting. Later, as time went on, there were more and more test sets, and the situation of overfitting was alleviated. This is indeed a relatively serious problem, but I guess there is one reason. When the number of iterations was 75000, the accuracy was a linear growth trend with time. This time this overfitting situation may be due to the number of iterations It ’s relatively small, but because my computer ’s performance is not very good, if there are too many iterations, it takes about two or three hours to run a program, and the training results are also good and bad. The solution is to modify the neural network. Layer, increase the kernel of the third and fourth layers a little, and then the filter increases."
      ]
    }
  ]
}